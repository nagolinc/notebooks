{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1v7y5YcM4fUAyHn-a59vxRLRfvgsv2X8P",
      "authorship_tag": "ABX9TyMu29aF+6BSQo505HB7VEf5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "premium"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nagolinc/notebooks/blob/main/cycle_diffsuion.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "gUDnq8sbcEGs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "57601e13-fa8e-47e4-c95d-1ca2b41b73d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fri Oct 21 18:58:21 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  A100-SXM4-40GB      Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   28C    P0    44W / 400W |      0MiB / 40536MiB |      0%      Default |\n",
            "|                               |                      |             Disabled |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wandb"
      ],
      "metadata": {
        "id": "3SR7XERbDBHX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8d9379bf-46b0-45ca-9537-3fbd79173709"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting wandb\n",
            "  Downloading wandb-0.13.4-py2.py3-none-any.whl (1.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.9 MB 4.7 MB/s \n",
            "\u001b[?25hCollecting docker-pycreds>=0.4.0\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Collecting sentry-sdk>=1.0.0\n",
            "  Downloading sentry_sdk-1.10.1-py2.py3-none-any.whl (166 kB)\n",
            "\u001b[K     |████████████████████████████████| 166 kB 80.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.23.0)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (5.4.8)\n",
            "Requirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (7.1.2)\n",
            "Collecting setproctitle\n",
            "  Downloading setproctitle-1.3.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
            "Requirement already satisfied: protobuf!=4.0.*,!=4.21.0,<5,>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.17.3)\n",
            "Collecting pathtools\n",
            "  Downloading pathtools-0.1.2.tar.gz (11 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from wandb) (57.4.0)\n",
            "Collecting GitPython>=1.0.0\n",
            "  Downloading GitPython-3.1.29-py3-none-any.whl (182 kB)\n",
            "\u001b[K     |████████████████████████████████| 182 kB 79.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from wandb) (6.0)\n",
            "Requirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.3)\n",
            "Collecting shortuuid>=0.5.0\n",
            "  Downloading shortuuid-1.0.9-py3-none-any.whl (9.4 kB)\n",
            "Requirement already satisfied: six>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.15.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from GitPython>=1.0.0->wandb) (4.1.1)\n",
            "Collecting gitdb<5,>=4.0.1\n",
            "  Downloading gitdb-4.0.9-py3-none-any.whl (63 kB)\n",
            "\u001b[K     |████████████████████████████████| 63 kB 2.0 MB/s \n",
            "\u001b[?25hCollecting smmap<6,>=3.0.1\n",
            "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2022.9.24)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (1.24.3)\n",
            "Collecting sentry-sdk>=1.0.0\n",
            "  Downloading sentry_sdk-1.10.0-py2.py3-none-any.whl (166 kB)\n",
            "\u001b[K     |████████████████████████████████| 166 kB 84.1 MB/s \n",
            "\u001b[?25h  Downloading sentry_sdk-1.9.10-py2.py3-none-any.whl (162 kB)\n",
            "\u001b[K     |████████████████████████████████| 162 kB 87.8 MB/s \n",
            "\u001b[?25h  Downloading sentry_sdk-1.9.9-py2.py3-none-any.whl (162 kB)\n",
            "\u001b[K     |████████████████████████████████| 162 kB 85.5 MB/s \n",
            "\u001b[?25h  Downloading sentry_sdk-1.9.8-py2.py3-none-any.whl (158 kB)\n",
            "\u001b[K     |████████████████████████████████| 158 kB 84.8 MB/s \n",
            "\u001b[?25h  Downloading sentry_sdk-1.9.7-py2.py3-none-any.whl (157 kB)\n",
            "\u001b[K     |████████████████████████████████| 157 kB 90.0 MB/s \n",
            "\u001b[?25h  Downloading sentry_sdk-1.9.6-py2.py3-none-any.whl (157 kB)\n",
            "\u001b[K     |████████████████████████████████| 157 kB 84.8 MB/s \n",
            "\u001b[?25h  Downloading sentry_sdk-1.9.5-py2.py3-none-any.whl (157 kB)\n",
            "\u001b[K     |████████████████████████████████| 157 kB 85.3 MB/s \n",
            "\u001b[?25h  Downloading sentry_sdk-1.9.4-py2.py3-none-any.whl (157 kB)\n",
            "\u001b[K     |████████████████████████████████| 157 kB 84.8 MB/s \n",
            "\u001b[?25h  Downloading sentry_sdk-1.9.3-py2.py3-none-any.whl (157 kB)\n",
            "\u001b[K     |████████████████████████████████| 157 kB 83.7 MB/s \n",
            "\u001b[?25h  Downloading sentry_sdk-1.9.2-py2.py3-none-any.whl (157 kB)\n",
            "\u001b[K     |████████████████████████████████| 157 kB 85.0 MB/s \n",
            "\u001b[?25h  Downloading sentry_sdk-1.9.1-py2.py3-none-any.whl (157 kB)\n",
            "\u001b[K     |████████████████████████████████| 157 kB 84.6 MB/s \n",
            "\u001b[?25h  Downloading sentry_sdk-1.9.0-py2.py3-none-any.whl (156 kB)\n",
            "\u001b[K     |████████████████████████████████| 156 kB 83.4 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pathtools\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8806 sha256=b0af30d220f14317a2bdaa166e644f83f3772658df3d2f8f02ef143b58b7091d\n",
            "  Stored in directory: /root/.cache/pip/wheels/3e/31/09/fa59cef12cdcfecc627b3d24273699f390e71828921b2cbba2\n",
            "Successfully built pathtools\n",
            "Installing collected packages: smmap, gitdb, shortuuid, setproctitle, sentry-sdk, pathtools, GitPython, docker-pycreds, wandb\n",
            "Successfully installed GitPython-3.1.29 docker-pycreds-0.4.0 gitdb-4.0.9 pathtools-0.1.2 sentry-sdk-1.9.0 setproctitle-1.3.2 shortuuid-1.0.9 smmap-5.0.0 wandb-0.13.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wandb login"
      ],
      "metadata": {
        "id": "fwtNEv5YC2an",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6ac07fde-d240-4e0c-ba28-ffdc51638b5e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# you will need to create a project in wandb and edit these variables!"
      ],
      "metadata": {
        "id": "XmT9OQcN8lz0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%env WANDB_PROJECT=test\n",
        "%env WANDB_ENTITY=nagolinc"
      ],
      "metadata": {
        "id": "7BsVdHnDVV90",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "47235190-04d1-41a2-d905-1979697b4df9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "env: WANDB_PROJECT=test\n",
            "env: WANDB_ENTITY=nagolinc\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# install a ton of stuff"
      ],
      "metadata": {
        "id": "Ejz5WFRI8bRJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "koMYDeG6B3Cj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3592d21e-e494-4530-a9b9-613ae96e0add"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://github.com/openai/CLIP.git\n",
            "  Cloning https://github.com/openai/CLIP.git to /tmp/pip-req-build-0f7o1hmz\n",
            "  Running command git clone -q https://github.com/openai/CLIP.git /tmp/pip-req-build-0f7o1hmz\n",
            "Collecting ftfy\n",
            "  Downloading ftfy-6.1.1-py3-none-any.whl (53 kB)\n",
            "\u001b[K     |████████████████████████████████| 53 kB 1.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from clip==1.0) (2022.6.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from clip==1.0) (4.64.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from clip==1.0) (1.12.1+cu113)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from clip==1.0) (0.13.1+cu113)\n",
            "Requirement already satisfied: wcwidth>=0.2.5 in /usr/local/lib/python3.7/dist-packages (from ftfy->clip==1.0) (0.2.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->clip==1.0) (4.1.1)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision->clip==1.0) (7.1.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchvision->clip==1.0) (2.23.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision->clip==1.0) (1.21.6)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision->clip==1.0) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision->clip==1.0) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision->clip==1.0) (2022.9.24)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision->clip==1.0) (1.24.3)\n",
            "Building wheels for collected packages: clip\n",
            "  Building wheel for clip (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for clip: filename=clip-1.0-py3-none-any.whl size=1369409 sha256=119bfb7c3a8875f74fe2b88342f00a48efb63da856ce30e894a2e4b4543e3715\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-logakid2/wheels/fd/b9/c3/5b4470e35ed76e174bff77c92f91da82098d5e35fd5bc8cdac\n",
            "Successfully built clip\n",
            "Installing collected packages: ftfy, clip\n",
            "Successfully installed clip-1.0 ftfy-6.1.1\n"
          ]
        }
      ],
      "source": [
        "!pip install git+https://github.com/openai/CLIP.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/CompVis/taming-transformers.git"
      ],
      "metadata": {
        "id": "-mktF_1RCEho",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e8f0c61c-ca78-4e93-d2f2-b3bb2abcb723"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'taming-transformers'...\n",
            "remote: Enumerating objects: 1335, done.\u001b[K\n",
            "remote: Total 1335 (delta 0), reused 0 (delta 0), pack-reused 1335\u001b[K\n",
            "Receiving objects: 100% (1335/1335), 409.77 MiB | 68.22 MiB/s, done.\n",
            "Resolving deltas: 100% (279/279), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd taming-transformers/"
      ],
      "metadata": {
        "id": "5wX8KoR7CI7m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3cf16ac6-4c97-4a53-9d53-7944905ea27f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/taming-transformers\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install -e ."
      ],
      "metadata": {
        "id": "cLJkbUlgCKYO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cda738f6-290f-49c7-d106-c73850ebf649"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Obtaining file:///content/taming-transformers\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from taming-transformers==0.0.1) (1.12.1+cu113)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from taming-transformers==0.0.1) (1.21.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from taming-transformers==0.0.1) (4.64.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->taming-transformers==0.0.1) (4.1.1)\n",
            "Installing collected packages: taming-transformers\n",
            "  Running setup.py develop for taming-transformers\n",
            "Successfully installed taming-transformers-0.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets"
      ],
      "metadata": {
        "id": "Uvx9fACWS1Kn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aa4cd366-a9a1-43ae-d6b1-fa8b4466672b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting datasets\n",
            "  Downloading datasets-2.6.1-py3-none-any.whl (441 kB)\n",
            "\u001b[K     |████████████████████████████████| 441 kB 4.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: aiohttp in /usr/local/lib/python3.7/dist-packages (from datasets) (3.8.3)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.7/dist-packages (from datasets) (4.64.1)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from datasets) (4.13.0)\n",
            "Requirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.7/dist-packages (from datasets) (2022.8.2)\n",
            "Collecting multiprocess\n",
            "  Downloading multiprocess-0.70.13-py37-none-any.whl (115 kB)\n",
            "\u001b[K     |████████████████████████████████| 115 kB 82.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from datasets) (6.0)\n",
            "Collecting responses<0.19\n",
            "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets) (1.3.5)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (2.23.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from datasets) (21.3)\n",
            "Collecting huggingface-hub<1.0.0,>=0.2.0\n",
            "  Downloading huggingface_hub-0.10.1-py3-none-any.whl (163 kB)\n",
            "\u001b[K     |████████████████████████████████| 163 kB 82.9 MB/s \n",
            "\u001b[?25hCollecting xxhash\n",
            "  Downloading xxhash-3.1.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n",
            "\u001b[K     |████████████████████████████████| 212 kB 81.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: dill<0.3.6 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.3.5.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from datasets) (1.21.6)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.8.1)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: asynctest==0.13.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (0.13.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (4.1.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (22.1.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.2.0)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (4.0.2)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (6.0.2)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (2.1.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets) (3.8.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->datasets) (3.0.9)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2022.9.24)\n",
            "Collecting urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1\n",
            "  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n",
            "\u001b[K     |████████████████████████████████| 127 kB 83.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->datasets) (3.9.0)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2022.4)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n",
            "Installing collected packages: urllib3, xxhash, responses, multiprocess, huggingface-hub, datasets\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "Successfully installed datasets-2.6.1 huggingface-hub-0.10.1 multiprocess-0.70.13 responses-0.18.0 urllib3-1.25.11 xxhash-3.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "id": "1zOwpnKZS6mB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a5322d7-5328-424f-ae5f-b744f3ed44d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.23.1-py3-none-any.whl (5.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.3 MB 4.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.13.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.8.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.6 MB 70.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.10.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.9.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.9.24)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.25.11)\n",
            "Installing collected packages: tokenizers, transformers\n",
            "Successfully installed tokenizers-0.13.1 transformers-4.23.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install blobfile"
      ],
      "metadata": {
        "id": "xqiGYH6bWDbh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6b432053-98cb-4f2f-e3de-a55bc7736dd6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting blobfile\n",
            "  Downloading blobfile-2.0.0-py3-none-any.whl (73 kB)\n",
            "\u001b[K     |████████████████████████████████| 73 kB 1.5 MB/s \n",
            "\u001b[?25hCollecting pycryptodomex~=3.8\n",
            "  Downloading pycryptodomex-3.15.0-cp35-abi3-manylinux2010_x86_64.whl (2.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.3 MB 25.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock~=3.0 in /usr/local/lib/python3.7/dist-packages (from blobfile) (3.8.0)\n",
            "Requirement already satisfied: urllib3~=1.25 in /usr/local/lib/python3.7/dist-packages (from blobfile) (1.25.11)\n",
            "Requirement already satisfied: lxml~=4.9 in /usr/local/lib/python3.7/dist-packages (from blobfile) (4.9.1)\n",
            "Installing collected packages: pycryptodomex, blobfile\n",
            "Successfully installed blobfile-2.0.0 pycryptodomex-3.15.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install OmegaConf"
      ],
      "metadata": {
        "id": "VSPOUauTWS-x",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        },
        "outputId": "6ff13cab-4558-4451-ca37-2c0b86d33135"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting OmegaConf\n",
            "  Downloading omegaconf-2.2.3-py3-none-any.whl (79 kB)\n",
            "\u001b[K     |████████████████████████████████| 79 kB 3.4 MB/s \n",
            "\u001b[?25hCollecting antlr4-python3-runtime==4.9.*\n",
            "  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n",
            "\u001b[K     |████████████████████████████████| 117 kB 25.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.1.0 in /usr/local/lib/python3.7/dist-packages (from OmegaConf) (6.0)\n",
            "Building wheels for collected packages: antlr4-python3-runtime\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144575 sha256=e40eb7a6eefa5801e1ee5cad9e5762695f6893dae7f450ddefdec2ca348d0f81\n",
            "  Stored in directory: /root/.cache/pip/wheels/8b/8d/53/2af8772d9aec614e3fc65e53d4a993ad73c61daa8bbd85a873\n",
            "Successfully built antlr4-python3-runtime\n",
            "Installing collected packages: antlr4-python3-runtime, OmegaConf\n",
            "Successfully installed OmegaConf-2.2.3 antlr4-python3-runtime-4.9.3\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "pydevd_plugins"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install einops"
      ],
      "metadata": {
        "id": "uiSchMqxWeZX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d19f8a1d-2938-42a2-dd25-7cdaf5adc217"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting einops\n",
            "  Downloading einops-0.5.0-py3-none-any.whl (36 kB)\n",
            "Installing collected packages: einops\n",
            "Successfully installed einops-0.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pytorch_lightning"
      ],
      "metadata": {
        "id": "lpYSOQJUWldW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cf37f598-fa91-4b02-899b-139b4ad5367f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pytorch_lightning\n",
            "  Downloading pytorch_lightning-1.7.7-py3-none-any.whl (708 kB)\n",
            "\u001b[K     |████████████████████████████████| 708 kB 4.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorboard>=2.9.1 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning) (2.9.1)\n",
            "Collecting pyDeprecate>=0.3.1\n",
            "  Downloading pyDeprecate-0.3.2-py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: PyYAML>=5.4 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning) (6.0)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning) (4.1.1)\n",
            "Requirement already satisfied: torch>=1.9.* in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning) (1.12.1+cu113)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning) (21.3)\n",
            "Collecting torchmetrics>=0.7.0\n",
            "  Downloading torchmetrics-0.10.0-py3-none-any.whl (529 kB)\n",
            "\u001b[K     |████████████████████████████████| 529 kB 69.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning) (1.21.6)\n",
            "Requirement already satisfied: fsspec[http]!=2021.06.0,>=2021.05.0 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning) (2022.8.2)\n",
            "Requirement already satisfied: tqdm>=4.57.0 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning) (4.64.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (2.23.0)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.7/dist-packages (from fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (3.8.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (22.1.0)\n",
            "Requirement already satisfied: asynctest==0.13.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (0.13.0)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (2.1.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (6.0.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (1.8.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.7/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (1.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.7/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (4.0.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=17.0->pytorch_lightning) (3.0.9)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.9.1->pytorch_lightning) (0.4.6)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.9.1->pytorch_lightning) (3.4.1)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.9.1->pytorch_lightning) (1.49.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.9.1->pytorch_lightning) (57.4.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.9.1->pytorch_lightning) (0.6.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.9.1->pytorch_lightning) (1.35.0)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.9.1->pytorch_lightning) (1.0.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.9.1->pytorch_lightning) (1.8.1)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.9.1->pytorch_lightning) (3.17.3)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.9.1->pytorch_lightning) (0.37.1)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.9.1->pytorch_lightning) (1.3.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->pytorch_lightning) (0.2.8)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->pytorch_lightning) (1.15.0)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->pytorch_lightning) (4.2.4)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->pytorch_lightning) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.9.1->pytorch_lightning) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard>=2.9.1->pytorch_lightning) (4.13.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard>=2.9.1->pytorch_lightning) (3.9.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.9.1->pytorch_lightning) (0.4.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (2022.9.24)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (1.25.11)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.9.1->pytorch_lightning) (3.2.1)\n",
            "Installing collected packages: torchmetrics, pyDeprecate, pytorch-lightning\n",
            "Successfully installed pyDeprecate-0.3.2 pytorch-lightning-1.7.7 torchmetrics-0.10.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install kornia"
      ],
      "metadata": {
        "id": "E5KcnkwXXqZJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0e735188-4bcb-4817-d455-3915e92bd8a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting kornia\n",
            "  Downloading kornia-0.6.8-py2.py3-none-any.whl (551 kB)\n",
            "\u001b[K     |████████████████████████████████| 551 kB 4.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch>=1.8.1 in /usr/local/lib/python3.7/dist-packages (from kornia) (1.12.1+cu113)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from kornia) (21.3)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.8.1->kornia) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->kornia) (3.0.9)\n",
            "Installing collected packages: kornia\n",
            "Successfully installed kornia-0.6.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content"
      ],
      "metadata": {
        "id": "BRwRx2sVFImR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "02bd8f91-4199-4369-cd2d-24763074631b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/ChenWu98/cycle-diffusion.git"
      ],
      "metadata": {
        "id": "ocnuHDTQJVrm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "532e47cc-40b8-4b37-bb4a-ac3fc7983c38"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'cycle-diffusion'...\n",
            "remote: Enumerating objects: 438, done.\u001b[K\n",
            "remote: Counting objects: 100% (351/351), done.\u001b[K\n",
            "remote: Compressing objects: 100% (212/212), done.\u001b[K\n",
            "remote: Total 438 (delta 142), reused 312 (delta 110), pack-reused 87\n",
            "Receiving objects: 100% (438/438), 51.60 MiB | 60.18 MiB/s, done.\n",
            "Resolving deltas: 100% (150/150), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd cycle-diffusion"
      ],
      "metadata": {
        "id": "69oBg-LUMBVc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5fa40e69-c13c-40bd-9934-719902cbafa6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/cycle-diffusion\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd ckpts/\n"
      ],
      "metadata": {
        "id": "gxoH5YqwDUG2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c23dafd7-7bce-4dec-de52-c2ed5939efc8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/cycle-diffusion/ckpts\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mkdir stable_diffusion\n"
      ],
      "metadata": {
        "id": "_SKu5aJrJuRn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# You need a copy of sd-v1-4.ckpt (I save one in my google drive for this)"
      ],
      "metadata": {
        "id": "D9nVnqtR9lxq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cp /content/drive/MyDrive/AI/models/sd-v1-4.ckpt /content/cycle-diffusion/ckpts/stable_diffusion"
      ],
      "metadata": {
        "id": "_M2pvg3yWxk1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/cycle-diffusion"
      ],
      "metadata": {
        "id": "fa6YbNrJMzCd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3ff9c76f-44d9-4ab9-acab-cd307ccf302f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/cycle-diffusion\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# And generate our image"
      ],
      "metadata": {
        "id": "7yHfumautb6w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://pbs.twimg.com/media/FfV8d2yXEAIgIKa?format=png"
      ],
      "metadata": {
        "id": "ZM2dzymC14yr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "67a7a236-f36c-46a4-d757-15db3fba4c3b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-10-21 19:16:17--  https://pbs.twimg.com/media/FfV8d2yXEAIgIKa?format=png\n",
            "Resolving pbs.twimg.com (pbs.twimg.com)... 72.21.91.70, 2606:2800:220:1410:489:141e:20bb:12f6\n",
            "Connecting to pbs.twimg.com (pbs.twimg.com)|72.21.91.70|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 408614 (399K) [image/png]\n",
            "Saving to: ‘FfV8d2yXEAIgIKa?format=png’\n",
            "\n",
            "\r          FfV8d2yXE   0%[                    ]       0  --.-KB/s               \rFfV8d2yXEAIgIKa?for 100%[===================>] 399.04K  --.-KB/s    in 0.03s   \n",
            "\n",
            "2022-10-21 19:16:17 (11.6 MB/s) - ‘FfV8d2yXEAIgIKa?format=png’ saved [408614/408614]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#edit data/translate-text.json\n",
        "with open(\"/content/cycle-diffusion/data/translate-text.json\",'w') as f:\n",
        "  f.write(\"\"\"[\n",
        "    {\n",
        "        \"encode_text\": \"A photo of Barack Obama\",\n",
        "        \"decode_text\": \"A photo of Barack Obama smiling big grin\",\n",
        "        \"img_path\": \"/content/cycle-diffusion/FfV8d2yXEAIgIKa?format=png\"\n",
        "    }\n",
        "]\"\"\")"
      ],
      "metadata": {
        "id": "yERQf8FX3eQD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#edit data/translate-text.json\n",
        "with open(\"/content/cycle-diffusion/data/translate-text.json\",'w') as f:\n",
        "  f.write(\"\"\"[\n",
        "    {\n",
        "        \"encode_text\": \"A photo of a man\",\n",
        "        \"decode_text\": \"A photo of a man shouting in excitement\",\n",
        "        \"img_path\": \"/content/tmp5youud40.png\"\n",
        "    }\n",
        "]\"\"\")"
      ],
      "metadata": {
        "id": "tE2Z5ubl5nQL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"/content/cycle-diffusion/config/experiments/translate_text2img256_stable_diffusion_stochastic_custom_1.cfg\",'w') as f:\n",
        "  f.write(\"\"\"[model]\n",
        "name = text_unsupervised_translation\n",
        "\n",
        "[gan]\n",
        "gan_type = SDStochasticText\n",
        "source_model_type = sd-v1-4.ckpt\n",
        "custom_steps = 99\n",
        "white_box_steps = 100\n",
        "eta = 0.1\n",
        "encoder_unconditional_guidance_scales = [1]\n",
        "#this is how strongly the prompt will effect the image (3-5-ish is a good value)\n",
        "decoder_unconditional_guidance_scales = [5]\n",
        "#increase number of generations (only the best will be output)\n",
        "n_trials = 1\n",
        "#how may diffusion steps to skip (higher=fine grained changes only)\n",
        "skip_steps = [20]\n",
        "\n",
        "[raw_data]\n",
        "upsample_temp = 1\n",
        "#don't change this!\n",
        "range = [0, 500]\n",
        "\n",
        "[arg_paths]\n",
        "translate = tasks/translate_text512.cfg\n",
        "\n",
        "[PriorZEnergy]\n",
        "weight = 1\n",
        "\n",
        "[evaluation]\n",
        "evaluator_program = multi_task\n",
        "\n",
        "[visualization]\n",
        "visualizer_program = multi_image\"\"\")"
      ],
      "metadata": {
        "id": "6Uf3qsJXhRvI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%env CUDA_VISIBLE_DEVICES=0\n",
        "%env RUN_NAME=translate_text2img256_stable_diffusion_stochastic_custom_1\n",
        "%env SEED=1\n",
        "!python -m torch.distributed.launch --nproc_per_node 1 --master_port 1405 main.py --seed $SEED \\\n",
        " --cfg experiments/$RUN_NAME.cfg \\\n",
        " --run_name $RUN_NAME$SEED \\\n",
        " --logging_strategy steps \\\n",
        " --logging_first_step true \\\n",
        " --logging_steps 4 \\\n",
        " --evaluation_strategy steps \\\n",
        " --eval_steps 50 \\\n",
        " --metric_for_best_model CLIPEnergy \\\n",
        " --greater_is_better false \\\n",
        " --save_strategy steps \\\n",
        " --save_steps 50 \\\n",
        " --save_total_limit 1 \\\n",
        " --load_best_model_at_end \\\n",
        " --gradient_accumulation_steps 4 \\\n",
        " --num_train_epochs 0 \\\n",
        " --adafactor false \\\n",
        " --learning_rate 1e-3 \\\n",
        " --do_eval \\\n",
        " --output_dir output/$RUN_NAME$SEED \\\n",
        " --overwrite_output_dir \\\n",
        " --per_device_train_batch_size 1 \\\n",
        " --per_device_eval_batch_size 4 \\\n",
        " --eval_accumulation_steps 4 \\\n",
        " --ddp_find_unused_parameters true \\\n",
        " --verbose true"
      ],
      "metadata": {
        "id": "rhGeAmtWtRaJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "171872be-2dc2-4402-8ce5-0f02880ae8b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "env: CUDA_VISIBLE_DEVICES=0\n",
            "env: RUN_NAME=translate_text2img256_stable_diffusion_stochastic_custom_1\n",
            "env: SEED=1\n",
            "/usr/local/lib/python3.7/dist-packages/torch/distributed/launch.py:186: FutureWarning: The module torch.distributed.launch is deprecated\n",
            "and will be removed in future. Use torchrun.\n",
            "Note that --use_env is set by default in torchrun.\n",
            "If your script expects `--local_rank` argument to be set, please\n",
            "change it to read from `os.environ['LOCAL_RANK']` instead. See \n",
            "https://pytorch.org/docs/stable/distributed.html#launch-utility for \n",
            "further instructions\n",
            "\n",
            "  FutureWarning,\n",
            "2022-10-21 19:50:21.292487: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mnagolinc\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.13.4\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/cycle-diffusion/wandb/run-20221021_195025-b6q4ho71\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mtranslate_text2img256_stable_diffusion_stochastic_custom_11\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/nagolinc/test\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/nagolinc/test/runs/b6q4ho71\u001b[0m\n",
            "WARNING:datasets.builder:Found cached dataset empty (/content/cycle-diffusion/./data/empty/default/0.0.0/d752142030fdcb74be1a99e21e979b6ef62dcef1fd3755e354507be154bec9ec)\n",
            "100% 3/3 [00:00<00:00, 846.02it/s]\n",
            "First of all, when the code changes, make sure that no part in the model is under no_grad!\n",
            "{'model': {'base_learning_rate': 0.0001, 'target': 'ldm.models.diffusion.ddpm.LatentDiffusion', 'params': {'linear_start': 0.00085, 'linear_end': 0.012, 'num_timesteps_cond': 1, 'log_every_t': 200, 'timesteps': 1000, 'first_stage_key': 'jpg', 'cond_stage_key': 'txt', 'image_size': 64, 'channels': 4, 'cond_stage_trainable': False, 'conditioning_key': 'crossattn', 'monitor': 'val/loss_simple_ema', 'scale_factor': 0.18215, 'use_ema': False, 'scheduler_config': {'target': 'ldm.lr_scheduler.LambdaLinearScheduler', 'params': {'warm_up_steps': [10000], 'cycle_lengths': [10000000000000], 'f_start': [1e-06], 'f_max': [1.0], 'f_min': [1.0]}}, 'unet_config': {'target': 'ldm.modules.diffusionmodules.openaimodel.UNetModel', 'params': {'image_size': 32, 'in_channels': 4, 'out_channels': 4, 'model_channels': 320, 'attention_resolutions': [4, 2, 1], 'num_res_blocks': 2, 'channel_mult': [1, 2, 4, 4], 'num_heads': 8, 'use_spatial_transformer': True, 'transformer_depth': 1, 'context_dim': 768, 'use_checkpoint': True, 'legacy': False}}, 'first_stage_config': {'target': 'ldm.models.autoencoder.AutoencoderKL', 'params': {'embed_dim': 4, 'monitor': 'val/rec_loss', 'ddconfig': {'double_z': True, 'z_channels': 4, 'resolution': 256, 'in_channels': 3, 'out_ch': 3, 'ch': 128, 'ch_mult': [1, 2, 4, 4], 'num_res_blocks': 2, 'attn_resolutions': [], 'dropout': 0.0}, 'lossconfig': {'target': 'torch.nn.Identity'}}}, 'cond_stage_config': {'target': 'ldm.modules.encoders.modules.FrozenCLIPEmbedder'}}}}\n",
            "Loading model from ckpts/stable_diffusion/sd-v1-4.ckpt\n",
            "Global Step: 470000\n",
            "LatentDiffusion: Running in eps-prediction mode\n",
            "DiffusionWrapper has 859.52 M params.\n",
            "making attention of type 'vanilla' with 512 in_channels\n",
            "Working with z of shape (1, 4, 32, 32) = 4096 dimensions.\n",
            "making attention of type 'vanilla' with 512 in_channels\n",
            "Some weights of the model checkpoint at openai/clip-vit-large-patch14 were not used when initializing CLIPTextModel: ['vision_model.encoder.layers.19.self_attn.out_proj.weight', 'vision_model.encoder.layers.15.layer_norm1.weight', 'vision_model.encoder.layers.16.layer_norm2.bias', 'vision_model.encoder.layers.13.layer_norm2.bias', 'vision_model.encoder.layers.6.self_attn.v_proj.weight', 'vision_model.encoder.layers.22.mlp.fc2.weight', 'vision_model.encoder.layers.12.mlp.fc1.weight', 'vision_model.encoder.layers.22.self_attn.out_proj.weight', 'vision_model.post_layernorm.weight', 'vision_model.encoder.layers.22.self_attn.k_proj.weight', 'vision_model.encoder.layers.10.layer_norm1.weight', 'vision_model.encoder.layers.23.layer_norm2.bias', 'vision_model.encoder.layers.6.mlp.fc2.bias', 'vision_model.encoder.layers.19.layer_norm1.bias', 'vision_model.encoder.layers.6.self_attn.q_proj.weight', 'vision_model.encoder.layers.23.self_attn.out_proj.weight', 'vision_model.encoder.layers.9.mlp.fc2.bias', 'vision_model.encoder.layers.19.mlp.fc1.bias', 'vision_model.encoder.layers.14.layer_norm1.bias', 'vision_model.encoder.layers.7.self_attn.v_proj.bias', 'vision_model.encoder.layers.0.layer_norm1.bias', 'vision_model.encoder.layers.16.mlp.fc1.weight', 'vision_model.encoder.layers.3.mlp.fc2.bias', 'vision_model.encoder.layers.20.self_attn.q_proj.bias', 'vision_model.encoder.layers.2.mlp.fc2.bias', 'vision_model.encoder.layers.6.self_attn.k_proj.weight', 'vision_model.encoder.layers.15.mlp.fc2.weight', 'vision_model.encoder.layers.13.mlp.fc1.bias', 'vision_model.encoder.layers.7.self_attn.out_proj.weight', 'vision_model.encoder.layers.19.self_attn.q_proj.weight', 'vision_model.encoder.layers.20.self_attn.q_proj.weight', 'vision_model.encoder.layers.17.self_attn.out_proj.bias', 'vision_model.encoder.layers.23.mlp.fc1.bias', 'vision_model.encoder.layers.13.self_attn.q_proj.bias', 'vision_model.encoder.layers.22.self_attn.q_proj.weight', 'vision_model.encoder.layers.1.layer_norm2.bias', 'vision_model.encoder.layers.19.self_attn.v_proj.weight', 'vision_model.encoder.layers.1.self_attn.q_proj.bias', 'vision_model.encoder.layers.21.layer_norm2.weight', 'vision_model.encoder.layers.5.mlp.fc1.bias', 'vision_model.encoder.layers.6.layer_norm1.bias', 'vision_model.encoder.layers.1.self_attn.k_proj.weight', 'vision_model.encoder.layers.18.self_attn.out_proj.weight', 'vision_model.encoder.layers.15.mlp.fc2.bias', 'vision_model.encoder.layers.11.layer_norm1.weight', 'vision_model.encoder.layers.16.self_attn.out_proj.weight', 'vision_model.encoder.layers.17.mlp.fc1.weight', 'vision_model.encoder.layers.18.mlp.fc1.weight', 'vision_model.encoder.layers.2.mlp.fc1.weight', 'vision_model.encoder.layers.17.self_attn.q_proj.bias', 'vision_model.encoder.layers.15.self_attn.k_proj.bias', 'vision_model.encoder.layers.11.mlp.fc2.weight', 'vision_model.encoder.layers.19.self_attn.q_proj.bias', 'vision_model.encoder.layers.19.self_attn.out_proj.bias', 'vision_model.encoder.layers.15.mlp.fc1.weight', 'vision_model.encoder.layers.4.self_attn.q_proj.bias', 'vision_model.encoder.layers.7.layer_norm1.bias', 'vision_model.encoder.layers.20.mlp.fc1.weight', 'vision_model.encoder.layers.9.mlp.fc2.weight', 'vision_model.encoder.layers.6.layer_norm1.weight', 'vision_model.encoder.layers.10.self_attn.k_proj.bias', 'vision_model.encoder.layers.7.mlp.fc2.bias', 'vision_model.encoder.layers.12.self_attn.k_proj.weight', 'vision_model.encoder.layers.23.self_attn.q_proj.weight', 'vision_model.encoder.layers.5.self_attn.v_proj.weight', 'vision_model.encoder.layers.13.mlp.fc2.bias', 'vision_model.encoder.layers.23.self_attn.q_proj.bias', 'vision_model.encoder.layers.14.layer_norm1.weight', 'vision_model.encoder.layers.15.self_attn.out_proj.bias', 'vision_model.embeddings.position_ids', 'vision_model.encoder.layers.13.layer_norm1.bias', 'vision_model.encoder.layers.10.layer_norm2.bias', 'vision_model.encoder.layers.14.self_attn.k_proj.bias', 'vision_model.encoder.layers.13.self_attn.out_proj.weight', 'vision_model.encoder.layers.2.self_attn.q_proj.bias', 'vision_model.encoder.layers.1.layer_norm2.weight', 'vision_model.encoder.layers.1.mlp.fc2.weight', 'vision_model.encoder.layers.6.mlp.fc1.bias', 'vision_model.encoder.layers.1.self_attn.out_proj.bias', 'vision_model.encoder.layers.22.self_attn.k_proj.bias', 'vision_model.encoder.layers.5.mlp.fc2.weight', 'vision_model.encoder.layers.3.self_attn.out_proj.bias', 'vision_model.encoder.layers.4.layer_norm1.bias', 'vision_model.encoder.layers.13.self_attn.q_proj.weight', 'vision_model.encoder.layers.8.self_attn.v_proj.bias', 'vision_model.encoder.layers.8.self_attn.q_proj.bias', 'vision_model.encoder.layers.5.mlp.fc2.bias', 'vision_model.encoder.layers.3.self_attn.k_proj.weight', 'vision_model.encoder.layers.11.self_attn.v_proj.bias', 'vision_model.encoder.layers.10.self_attn.v_proj.weight', 'vision_model.encoder.layers.8.self_attn.out_proj.weight', 'vision_model.encoder.layers.21.self_attn.out_proj.bias', 'vision_model.encoder.layers.4.mlp.fc2.weight', 'vision_model.encoder.layers.12.layer_norm2.weight', 'vision_model.encoder.layers.20.self_attn.k_proj.bias', 'vision_model.encoder.layers.12.layer_norm1.weight', 'vision_model.encoder.layers.17.self_attn.v_proj.bias', 'vision_model.encoder.layers.20.self_attn.out_proj.bias', 'vision_model.encoder.layers.19.mlp.fc2.bias', 'vision_model.encoder.layers.18.layer_norm1.bias', 'vision_model.encoder.layers.6.mlp.fc1.weight', 'vision_model.encoder.layers.8.mlp.fc1.weight', 'vision_model.encoder.layers.10.mlp.fc1.weight', 'vision_model.encoder.layers.20.self_attn.out_proj.weight', 'vision_model.encoder.layers.11.layer_norm2.weight', 'vision_model.encoder.layers.16.self_attn.k_proj.bias', 'vision_model.encoder.layers.18.self_attn.k_proj.bias', 'vision_model.encoder.layers.6.self_attn.v_proj.bias', 'vision_model.encoder.layers.22.self_attn.out_proj.bias', 'vision_model.encoder.layers.7.self_attn.out_proj.bias', 'vision_model.encoder.layers.23.mlp.fc1.weight', 'vision_model.encoder.layers.9.layer_norm1.weight', 'vision_model.encoder.layers.3.self_attn.v_proj.bias', 'vision_model.encoder.layers.21.layer_norm1.weight', 'vision_model.encoder.layers.19.self_attn.k_proj.weight', 'vision_model.encoder.layers.17.layer_norm2.weight', 'vision_model.encoder.layers.20.layer_norm1.weight', 'vision_model.encoder.layers.4.self_attn.k_proj.weight', 'vision_model.encoder.layers.21.mlp.fc1.bias', 'vision_model.encoder.layers.19.mlp.fc2.weight', 'vision_model.post_layernorm.bias', 'logit_scale', 'vision_model.encoder.layers.17.self_attn.out_proj.weight', 'vision_model.encoder.layers.14.self_attn.q_proj.weight', 'vision_model.encoder.layers.8.layer_norm2.bias', 'vision_model.encoder.layers.21.self_attn.q_proj.weight', 'vision_model.encoder.layers.16.layer_norm1.bias', 'vision_model.encoder.layers.23.self_attn.k_proj.bias', 'vision_model.encoder.layers.21.self_attn.v_proj.weight', 'vision_model.encoder.layers.21.layer_norm2.bias', 'vision_model.embeddings.position_embedding.weight', 'vision_model.encoder.layers.16.layer_norm2.weight', 'vision_model.encoder.layers.22.layer_norm1.bias', 'vision_model.encoder.layers.6.mlp.fc2.weight', 'vision_model.encoder.layers.1.mlp.fc1.weight', 'vision_model.encoder.layers.4.self_attn.out_proj.weight', 'vision_model.encoder.layers.7.mlp.fc1.bias', 'vision_model.encoder.layers.13.mlp.fc2.weight', 'vision_model.encoder.layers.3.self_attn.v_proj.weight', 'vision_model.encoder.layers.14.mlp.fc1.weight', 'vision_model.encoder.layers.14.self_attn.v_proj.bias', 'vision_model.encoder.layers.12.self_attn.q_proj.weight', 'vision_model.encoder.layers.2.layer_norm1.weight', 'vision_model.encoder.layers.20.self_attn.v_proj.bias', 'vision_model.encoder.layers.5.self_attn.q_proj.bias', 'vision_model.encoder.layers.23.layer_norm1.weight', 'vision_model.encoder.layers.2.mlp.fc1.bias', 'vision_model.encoder.layers.10.self_attn.out_proj.weight', 'vision_model.encoder.layers.23.self_attn.k_proj.weight', 'vision_model.encoder.layers.9.mlp.fc1.weight', 'vision_model.encoder.layers.6.self_attn.out_proj.weight', 'vision_model.encoder.layers.20.self_attn.k_proj.weight', 'vision_model.encoder.layers.3.layer_norm2.weight', 'vision_model.encoder.layers.22.layer_norm1.weight', 'vision_model.encoder.layers.11.self_attn.q_proj.bias', 'vision_model.encoder.layers.1.self_attn.v_proj.weight', 'vision_model.encoder.layers.11.mlp.fc1.bias', 'vision_model.encoder.layers.2.layer_norm1.bias', 'vision_model.encoder.layers.22.layer_norm2.bias', 'vision_model.encoder.layers.11.self_attn.out_proj.bias', 'vision_model.encoder.layers.21.self_attn.k_proj.weight', 'vision_model.encoder.layers.1.layer_norm1.bias', 'vision_model.encoder.layers.1.mlp.fc2.bias', 'vision_model.encoder.layers.18.layer_norm1.weight', 'vision_model.encoder.layers.4.layer_norm2.bias', 'vision_model.encoder.layers.0.layer_norm2.bias', 'vision_model.encoder.layers.13.layer_norm2.weight', 'vision_model.pre_layrnorm.weight', 'vision_model.encoder.layers.7.self_attn.k_proj.weight', 'vision_model.encoder.layers.12.self_attn.out_proj.bias', 'vision_model.encoder.layers.11.self_attn.q_proj.weight', 'vision_model.encoder.layers.22.self_attn.v_proj.weight', 'vision_model.encoder.layers.18.self_attn.out_proj.bias', 'vision_model.encoder.layers.5.mlp.fc1.weight', 'vision_model.encoder.layers.23.self_attn.v_proj.bias', 'vision_model.encoder.layers.0.self_attn.out_proj.weight', 'vision_model.encoder.layers.12.layer_norm1.bias', 'vision_model.encoder.layers.16.self_attn.out_proj.bias', 'vision_model.encoder.layers.10.self_attn.k_proj.weight', 'vision_model.encoder.layers.7.mlp.fc1.weight', 'vision_model.encoder.layers.0.mlp.fc2.weight', 'vision_model.encoder.layers.8.layer_norm1.bias', 'visual_projection.weight', 'vision_model.encoder.layers.5.layer_norm2.weight', 'vision_model.encoder.layers.4.mlp.fc2.bias', 'vision_model.encoder.layers.12.self_attn.k_proj.bias', 'vision_model.encoder.layers.16.layer_norm1.weight', 'vision_model.encoder.layers.21.mlp.fc2.weight', 'vision_model.encoder.layers.22.mlp.fc1.bias', 'vision_model.encoder.layers.21.self_attn.out_proj.weight', 'vision_model.encoder.layers.21.self_attn.k_proj.bias', 'vision_model.encoder.layers.12.layer_norm2.bias', 'vision_model.encoder.layers.20.self_attn.v_proj.weight', 'vision_model.encoder.layers.10.self_attn.v_proj.bias', 'vision_model.encoder.layers.19.layer_norm1.weight', 'vision_model.encoder.layers.7.layer_norm2.weight', 'vision_model.encoder.layers.8.self_attn.out_proj.bias', 'vision_model.encoder.layers.5.self_attn.v_proj.bias', 'vision_model.encoder.layers.23.layer_norm1.bias', 'vision_model.encoder.layers.10.self_attn.q_proj.bias', 'vision_model.encoder.layers.3.layer_norm1.bias', 'vision_model.encoder.layers.18.mlp.fc1.bias', 'vision_model.encoder.layers.1.self_attn.v_proj.bias', 'vision_model.embeddings.patch_embedding.weight', 'vision_model.encoder.layers.14.layer_norm2.bias', 'vision_model.encoder.layers.15.self_attn.out_proj.weight', 'vision_model.encoder.layers.19.layer_norm2.bias', 'vision_model.encoder.layers.14.mlp.fc2.weight', 'vision_model.encoder.layers.17.self_attn.v_proj.weight', 'vision_model.encoder.layers.3.self_attn.k_proj.bias', 'vision_model.encoder.layers.9.self_attn.k_proj.bias', 'vision_model.encoder.layers.15.self_attn.v_proj.weight', 'vision_model.encoder.layers.0.self_attn.q_proj.bias', 'vision_model.encoder.layers.16.self_attn.v_proj.bias', 'vision_model.encoder.layers.20.mlp.fc2.bias', 'vision_model.encoder.layers.0.mlp.fc1.bias', 'vision_model.encoder.layers.13.self_attn.k_proj.bias', 'vision_model.encoder.layers.11.mlp.fc2.bias', 'vision_model.encoder.layers.17.layer_norm1.bias', 'vision_model.encoder.layers.3.self_attn.q_proj.weight', 'vision_model.encoder.layers.8.layer_norm2.weight', 'vision_model.encoder.layers.0.self_attn.v_proj.bias', 'vision_model.encoder.layers.12.self_attn.out_proj.weight', 'vision_model.encoder.layers.0.self_attn.v_proj.weight', 'vision_model.encoder.layers.3.layer_norm1.weight', 'vision_model.encoder.layers.19.mlp.fc1.weight', 'vision_model.encoder.layers.19.self_attn.k_proj.bias', 'vision_model.encoder.layers.0.self_attn.k_proj.weight', 'vision_model.encoder.layers.16.self_attn.q_proj.weight', 'vision_model.encoder.layers.0.self_attn.q_proj.weight', 'vision_model.encoder.layers.22.self_attn.v_proj.bias', 'vision_model.encoder.layers.2.self_attn.k_proj.bias', 'vision_model.encoder.layers.8.mlp.fc1.bias', 'vision_model.encoder.layers.8.mlp.fc2.weight', 'vision_model.encoder.layers.4.self_attn.v_proj.weight', 'vision_model.encoder.layers.11.layer_norm1.bias', 'vision_model.encoder.layers.4.layer_norm1.weight', 'vision_model.encoder.layers.4.mlp.fc1.weight', 'vision_model.encoder.layers.6.self_attn.out_proj.bias', 'vision_model.encoder.layers.4.self_attn.q_proj.weight', 'vision_model.encoder.layers.10.mlp.fc2.bias', 'vision_model.encoder.layers.1.self_attn.out_proj.weight', 'vision_model.encoder.layers.0.layer_norm1.weight', 'vision_model.encoder.layers.13.self_attn.out_proj.bias', 'vision_model.encoder.layers.3.mlp.fc1.weight', 'vision_model.encoder.layers.7.layer_norm2.bias', 'vision_model.encoder.layers.8.self_attn.k_proj.weight', 'vision_model.encoder.layers.14.self_attn.out_proj.weight', 'vision_model.encoder.layers.18.self_attn.k_proj.weight', 'vision_model.encoder.layers.11.self_attn.k_proj.bias', 'vision_model.encoder.layers.18.self_attn.q_proj.bias', 'vision_model.encoder.layers.12.mlp.fc1.bias', 'vision_model.encoder.layers.15.self_attn.q_proj.bias', 'vision_model.encoder.layers.17.layer_norm2.bias', 'vision_model.encoder.layers.13.self_attn.k_proj.weight', 'text_projection.weight', 'vision_model.encoder.layers.0.self_attn.out_proj.bias', 'vision_model.pre_layrnorm.bias', 'vision_model.encoder.layers.15.self_attn.q_proj.weight', 'vision_model.embeddings.class_embedding', 'vision_model.encoder.layers.18.self_attn.q_proj.weight', 'vision_model.encoder.layers.14.self_attn.k_proj.weight', 'vision_model.encoder.layers.14.self_attn.v_proj.weight', 'vision_model.encoder.layers.15.self_attn.k_proj.weight', 'vision_model.encoder.layers.1.self_attn.q_proj.weight', 'vision_model.encoder.layers.18.self_attn.v_proj.weight', 'vision_model.encoder.layers.10.mlp.fc1.bias', 'vision_model.encoder.layers.0.mlp.fc2.bias', 'vision_model.encoder.layers.2.layer_norm2.weight', 'vision_model.encoder.layers.23.self_attn.v_proj.weight', 'vision_model.encoder.layers.20.layer_norm1.bias', 'vision_model.encoder.layers.17.mlp.fc2.bias', 'vision_model.encoder.layers.17.mlp.fc2.weight', 'vision_model.encoder.layers.8.self_attn.q_proj.weight', 'vision_model.encoder.layers.16.self_attn.v_proj.weight', 'vision_model.encoder.layers.22.mlp.fc1.weight', 'vision_model.encoder.layers.21.mlp.fc1.weight', 'vision_model.encoder.layers.9.layer_norm2.weight', 'vision_model.encoder.layers.3.self_attn.out_proj.weight', 'vision_model.encoder.layers.2.self_attn.q_proj.weight', 'vision_model.encoder.layers.17.self_attn.k_proj.bias', 'vision_model.encoder.layers.3.layer_norm2.bias', 'vision_model.encoder.layers.11.self_attn.out_proj.weight', 'vision_model.encoder.layers.17.self_attn.k_proj.weight', 'vision_model.encoder.layers.13.self_attn.v_proj.weight', 'vision_model.encoder.layers.4.self_attn.k_proj.bias', 'vision_model.encoder.layers.7.self_attn.k_proj.bias', 'vision_model.encoder.layers.9.self_attn.q_proj.weight', 'vision_model.encoder.layers.16.mlp.fc1.bias', 'vision_model.encoder.layers.10.self_attn.q_proj.weight', 'vision_model.encoder.layers.10.layer_norm2.weight', 'vision_model.encoder.layers.3.self_attn.q_proj.bias', 'vision_model.encoder.layers.5.self_attn.out_proj.bias', 'vision_model.encoder.layers.23.self_attn.out_proj.bias', 'vision_model.encoder.layers.20.mlp.fc2.weight', 'vision_model.encoder.layers.21.self_attn.v_proj.bias', 'vision_model.encoder.layers.7.self_attn.q_proj.weight', 'vision_model.encoder.layers.6.self_attn.k_proj.bias', 'vision_model.encoder.layers.4.self_attn.out_proj.bias', 'vision_model.encoder.layers.21.layer_norm1.bias', 'vision_model.encoder.layers.8.layer_norm1.weight', 'vision_model.encoder.layers.13.self_attn.v_proj.bias', 'vision_model.encoder.layers.4.self_attn.v_proj.bias', 'vision_model.encoder.layers.14.self_attn.q_proj.bias', 'vision_model.encoder.layers.11.self_attn.k_proj.weight', 'vision_model.encoder.layers.12.self_attn.v_proj.bias', 'vision_model.encoder.layers.1.layer_norm1.weight', 'vision_model.encoder.layers.15.self_attn.v_proj.bias', 'vision_model.encoder.layers.7.mlp.fc2.weight', 'vision_model.encoder.layers.9.mlp.fc1.bias', 'vision_model.encoder.layers.12.self_attn.q_proj.bias', 'vision_model.encoder.layers.1.mlp.fc1.bias', 'vision_model.encoder.layers.11.mlp.fc1.weight', 'vision_model.encoder.layers.4.mlp.fc1.bias', 'vision_model.encoder.layers.15.layer_norm2.weight', 'vision_model.encoder.layers.14.self_attn.out_proj.bias', 'vision_model.encoder.layers.6.layer_norm2.weight', 'vision_model.encoder.layers.8.mlp.fc2.bias', 'vision_model.encoder.layers.11.layer_norm2.bias', 'vision_model.encoder.layers.17.mlp.fc1.bias', 'vision_model.encoder.layers.10.self_attn.out_proj.bias', 'vision_model.encoder.layers.15.mlp.fc1.bias', 'vision_model.encoder.layers.18.layer_norm2.bias', 'vision_model.encoder.layers.10.layer_norm1.bias', 'vision_model.encoder.layers.19.self_attn.v_proj.bias', 'vision_model.encoder.layers.5.self_attn.k_proj.bias', 'vision_model.encoder.layers.22.layer_norm2.weight', 'vision_model.encoder.layers.4.layer_norm2.weight', 'vision_model.encoder.layers.12.mlp.fc2.weight', 'vision_model.encoder.layers.9.layer_norm1.bias', 'vision_model.encoder.layers.22.self_attn.q_proj.bias', 'vision_model.encoder.layers.2.layer_norm2.bias', 'vision_model.encoder.layers.0.self_attn.k_proj.bias', 'vision_model.encoder.layers.5.layer_norm2.bias', 'vision_model.encoder.layers.18.self_attn.v_proj.bias', 'vision_model.encoder.layers.22.mlp.fc2.bias', 'vision_model.encoder.layers.18.mlp.fc2.bias', 'vision_model.encoder.layers.17.layer_norm1.weight', 'vision_model.encoder.layers.20.layer_norm2.weight', 'vision_model.encoder.layers.5.layer_norm1.weight', 'vision_model.encoder.layers.8.self_attn.v_proj.weight', 'vision_model.encoder.layers.14.mlp.fc2.bias', 'vision_model.encoder.layers.0.layer_norm2.weight', 'vision_model.encoder.layers.1.self_attn.k_proj.bias', 'vision_model.encoder.layers.23.mlp.fc2.weight', 'vision_model.encoder.layers.3.mlp.fc1.bias', 'vision_model.encoder.layers.19.layer_norm2.weight', 'vision_model.encoder.layers.6.layer_norm2.bias', 'vision_model.encoder.layers.2.self_attn.v_proj.bias', 'vision_model.encoder.layers.14.layer_norm2.weight', 'vision_model.encoder.layers.5.self_attn.q_proj.weight', 'vision_model.encoder.layers.9.self_attn.v_proj.weight', 'vision_model.encoder.layers.15.layer_norm2.bias', 'vision_model.encoder.layers.7.layer_norm1.weight', 'vision_model.encoder.layers.2.self_attn.out_proj.weight', 'vision_model.encoder.layers.8.self_attn.k_proj.bias', 'vision_model.encoder.layers.16.mlp.fc2.weight', 'vision_model.encoder.layers.11.self_attn.v_proj.weight', 'vision_model.encoder.layers.9.self_attn.v_proj.bias', 'vision_model.encoder.layers.16.self_attn.k_proj.weight', 'vision_model.encoder.layers.18.mlp.fc2.weight', 'vision_model.encoder.layers.20.layer_norm2.bias', 'vision_model.encoder.layers.9.layer_norm2.bias', 'vision_model.encoder.layers.20.mlp.fc1.bias', 'vision_model.encoder.layers.16.mlp.fc2.bias', 'vision_model.encoder.layers.3.mlp.fc2.weight', 'vision_model.encoder.layers.7.self_attn.v_proj.weight', 'vision_model.encoder.layers.21.self_attn.q_proj.bias', 'vision_model.encoder.layers.9.self_attn.out_proj.bias', 'vision_model.encoder.layers.12.self_attn.v_proj.weight', 'vision_model.encoder.layers.18.layer_norm2.weight', 'vision_model.encoder.layers.16.self_attn.q_proj.bias', 'vision_model.encoder.layers.12.mlp.fc2.bias', 'vision_model.encoder.layers.9.self_attn.q_proj.bias', 'vision_model.encoder.layers.2.self_attn.out_proj.bias', 'vision_model.encoder.layers.9.self_attn.out_proj.weight', 'vision_model.encoder.layers.5.self_attn.out_proj.weight', 'vision_model.encoder.layers.15.layer_norm1.bias', 'vision_model.encoder.layers.9.self_attn.k_proj.weight', 'vision_model.encoder.layers.2.self_attn.v_proj.weight', 'vision_model.encoder.layers.13.layer_norm1.weight', 'vision_model.encoder.layers.0.mlp.fc1.weight', 'vision_model.encoder.layers.10.mlp.fc2.weight', 'vision_model.encoder.layers.23.layer_norm2.weight', 'vision_model.encoder.layers.23.mlp.fc2.bias', 'vision_model.encoder.layers.14.mlp.fc1.bias', 'vision_model.encoder.layers.6.self_attn.q_proj.bias', 'vision_model.encoder.layers.21.mlp.fc2.bias', 'vision_model.encoder.layers.2.mlp.fc2.weight', 'vision_model.encoder.layers.5.self_attn.k_proj.weight', 'vision_model.encoder.layers.7.self_attn.q_proj.bias', 'vision_model.encoder.layers.5.layer_norm1.bias', 'vision_model.encoder.layers.13.mlp.fc1.weight', 'vision_model.encoder.layers.17.self_attn.q_proj.weight', 'vision_model.encoder.layers.2.self_attn.k_proj.weight']\n",
            "- This IS expected if you are initializing CLIPTextModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing CLIPTextModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "unexpected keys:\n",
            "['model_ema.decay', 'model_ema.num_updates']\n",
            "---------------------------------------------------------------------------\n",
            "resolution: 512\n",
            "Using DDIM sampling with 99 sampling steps and eta=0.1\n",
            "DistributedDataParallel(\n",
            "  (module): TextUnsupervisedTranslation(\n",
            "    (gan_wrapper): SDStochasticTextWrapper(\n",
            "      (generator): LatentDiffusion(\n",
            "        (model): DiffusionWrapper(\n",
            "          (diffusion_model): UNetModel(\n",
            "            (time_embed): Sequential(\n",
            "              (0): Linear(in_features=320, out_features=1280, bias=True)\n",
            "              (1): SiLU()\n",
            "              (2): Linear(in_features=1280, out_features=1280, bias=True)\n",
            "            )\n",
            "            (input_blocks): ModuleList(\n",
            "              (0): TimestepEmbedSequential(\n",
            "                (0): Conv2d(4, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "              )\n",
            "              (1): TimestepEmbedSequential(\n",
            "                (0): ResBlock(\n",
            "                  (in_layers): Sequential(\n",
            "                    (0): GroupNorm32(32, 320, eps=1e-05, affine=True)\n",
            "                    (1): SiLU()\n",
            "                    (2): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "                  )\n",
            "                  (h_upd): Identity()\n",
            "                  (x_upd): Identity()\n",
            "                  (emb_layers): Sequential(\n",
            "                    (0): SiLU()\n",
            "                    (1): Linear(in_features=1280, out_features=320, bias=True)\n",
            "                  )\n",
            "                  (out_layers): Sequential(\n",
            "                    (0): GroupNorm32(32, 320, eps=1e-05, affine=True)\n",
            "                    (1): SiLU()\n",
            "                    (2): Dropout(p=0, inplace=False)\n",
            "                    (3): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "                  )\n",
            "                  (skip_connection): Identity()\n",
            "                )\n",
            "                (1): SpatialTransformer(\n",
            "                  (norm): GroupNorm(32, 320, eps=1e-06, affine=True)\n",
            "                  (proj_in): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
            "                  (transformer_blocks): ModuleList(\n",
            "                    (0): BasicTransformerBlock(\n",
            "                      (attn1): CrossAttention(\n",
            "                        (to_q): Linear(in_features=320, out_features=320, bias=False)\n",
            "                        (to_k): Linear(in_features=320, out_features=320, bias=False)\n",
            "                        (to_v): Linear(in_features=320, out_features=320, bias=False)\n",
            "                        (to_out): Sequential(\n",
            "                          (0): Linear(in_features=320, out_features=320, bias=True)\n",
            "                          (1): Dropout(p=0.0, inplace=False)\n",
            "                        )\n",
            "                      )\n",
            "                      (ff): FeedForward(\n",
            "                        (net): Sequential(\n",
            "                          (0): GEGLU(\n",
            "                            (proj): Linear(in_features=320, out_features=2560, bias=True)\n",
            "                          )\n",
            "                          (1): Dropout(p=0.0, inplace=False)\n",
            "                          (2): Linear(in_features=1280, out_features=320, bias=True)\n",
            "                        )\n",
            "                      )\n",
            "                      (attn2): CrossAttention(\n",
            "                        (to_q): Linear(in_features=320, out_features=320, bias=False)\n",
            "                        (to_k): Linear(in_features=768, out_features=320, bias=False)\n",
            "                        (to_v): Linear(in_features=768, out_features=320, bias=False)\n",
            "                        (to_out): Sequential(\n",
            "                          (0): Linear(in_features=320, out_features=320, bias=True)\n",
            "                          (1): Dropout(p=0.0, inplace=False)\n",
            "                        )\n",
            "                      )\n",
            "                      (norm1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
            "                      (norm2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
            "                      (norm3): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
            "                    )\n",
            "                  )\n",
            "                  (proj_out): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
            "                )\n",
            "              )\n",
            "              (2): TimestepEmbedSequential(\n",
            "                (0): ResBlock(\n",
            "                  (in_layers): Sequential(\n",
            "                    (0): GroupNorm32(32, 320, eps=1e-05, affine=True)\n",
            "                    (1): SiLU()\n",
            "                    (2): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "                  )\n",
            "                  (h_upd): Identity()\n",
            "                  (x_upd): Identity()\n",
            "                  (emb_layers): Sequential(\n",
            "                    (0): SiLU()\n",
            "                    (1): Linear(in_features=1280, out_features=320, bias=True)\n",
            "                  )\n",
            "                  (out_layers): Sequential(\n",
            "                    (0): GroupNorm32(32, 320, eps=1e-05, affine=True)\n",
            "                    (1): SiLU()\n",
            "                    (2): Dropout(p=0, inplace=False)\n",
            "                    (3): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "                  )\n",
            "                  (skip_connection): Identity()\n",
            "                )\n",
            "                (1): SpatialTransformer(\n",
            "                  (norm): GroupNorm(32, 320, eps=1e-06, affine=True)\n",
            "                  (proj_in): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
            "                  (transformer_blocks): ModuleList(\n",
            "                    (0): BasicTransformerBlock(\n",
            "                      (attn1): CrossAttention(\n",
            "                        (to_q): Linear(in_features=320, out_features=320, bias=False)\n",
            "                        (to_k): Linear(in_features=320, out_features=320, bias=False)\n",
            "                        (to_v): Linear(in_features=320, out_features=320, bias=False)\n",
            "                        (to_out): Sequential(\n",
            "                          (0): Linear(in_features=320, out_features=320, bias=True)\n",
            "                          (1): Dropout(p=0.0, inplace=False)\n",
            "                        )\n",
            "                      )\n",
            "                      (ff): FeedForward(\n",
            "                        (net): Sequential(\n",
            "                          (0): GEGLU(\n",
            "                            (proj): Linear(in_features=320, out_features=2560, bias=True)\n",
            "                          )\n",
            "                          (1): Dropout(p=0.0, inplace=False)\n",
            "                          (2): Linear(in_features=1280, out_features=320, bias=True)\n",
            "                        )\n",
            "                      )\n",
            "                      (attn2): CrossAttention(\n",
            "                        (to_q): Linear(in_features=320, out_features=320, bias=False)\n",
            "                        (to_k): Linear(in_features=768, out_features=320, bias=False)\n",
            "                        (to_v): Linear(in_features=768, out_features=320, bias=False)\n",
            "                        (to_out): Sequential(\n",
            "                          (0): Linear(in_features=320, out_features=320, bias=True)\n",
            "                          (1): Dropout(p=0.0, inplace=False)\n",
            "                        )\n",
            "                      )\n",
            "                      (norm1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
            "                      (norm2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
            "                      (norm3): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
            "                    )\n",
            "                  )\n",
            "                  (proj_out): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
            "                )\n",
            "              )\n",
            "              (3): TimestepEmbedSequential(\n",
            "                (0): Downsample(\n",
            "                  (op): Conv2d(320, 320, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "                )\n",
            "              )\n",
            "              (4): TimestepEmbedSequential(\n",
            "                (0): ResBlock(\n",
            "                  (in_layers): Sequential(\n",
            "                    (0): GroupNorm32(32, 320, eps=1e-05, affine=True)\n",
            "                    (1): SiLU()\n",
            "                    (2): Conv2d(320, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "                  )\n",
            "                  (h_upd): Identity()\n",
            "                  (x_upd): Identity()\n",
            "                  (emb_layers): Sequential(\n",
            "                    (0): SiLU()\n",
            "                    (1): Linear(in_features=1280, out_features=640, bias=True)\n",
            "                  )\n",
            "                  (out_layers): Sequential(\n",
            "                    (0): GroupNorm32(32, 640, eps=1e-05, affine=True)\n",
            "                    (1): SiLU()\n",
            "                    (2): Dropout(p=0, inplace=False)\n",
            "                    (3): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "                  )\n",
            "                  (skip_connection): Conv2d(320, 640, kernel_size=(1, 1), stride=(1, 1))\n",
            "                )\n",
            "                (1): SpatialTransformer(\n",
            "                  (norm): GroupNorm(32, 640, eps=1e-06, affine=True)\n",
            "                  (proj_in): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
            "                  (transformer_blocks): ModuleList(\n",
            "                    (0): BasicTransformerBlock(\n",
            "                      (attn1): CrossAttention(\n",
            "                        (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
            "                        (to_k): Linear(in_features=640, out_features=640, bias=False)\n",
            "                        (to_v): Linear(in_features=640, out_features=640, bias=False)\n",
            "                        (to_out): Sequential(\n",
            "                          (0): Linear(in_features=640, out_features=640, bias=True)\n",
            "                          (1): Dropout(p=0.0, inplace=False)\n",
            "                        )\n",
            "                      )\n",
            "                      (ff): FeedForward(\n",
            "                        (net): Sequential(\n",
            "                          (0): GEGLU(\n",
            "                            (proj): Linear(in_features=640, out_features=5120, bias=True)\n",
            "                          )\n",
            "                          (1): Dropout(p=0.0, inplace=False)\n",
            "                          (2): Linear(in_features=2560, out_features=640, bias=True)\n",
            "                        )\n",
            "                      )\n",
            "                      (attn2): CrossAttention(\n",
            "                        (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
            "                        (to_k): Linear(in_features=768, out_features=640, bias=False)\n",
            "                        (to_v): Linear(in_features=768, out_features=640, bias=False)\n",
            "                        (to_out): Sequential(\n",
            "                          (0): Linear(in_features=640, out_features=640, bias=True)\n",
            "                          (1): Dropout(p=0.0, inplace=False)\n",
            "                        )\n",
            "                      )\n",
            "                      (norm1): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
            "                      (norm2): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
            "                      (norm3): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
            "                    )\n",
            "                  )\n",
            "                  (proj_out): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
            "                )\n",
            "              )\n",
            "              (5): TimestepEmbedSequential(\n",
            "                (0): ResBlock(\n",
            "                  (in_layers): Sequential(\n",
            "                    (0): GroupNorm32(32, 640, eps=1e-05, affine=True)\n",
            "                    (1): SiLU()\n",
            "                    (2): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "                  )\n",
            "                  (h_upd): Identity()\n",
            "                  (x_upd): Identity()\n",
            "                  (emb_layers): Sequential(\n",
            "                    (0): SiLU()\n",
            "                    (1): Linear(in_features=1280, out_features=640, bias=True)\n",
            "                  )\n",
            "                  (out_layers): Sequential(\n",
            "                    (0): GroupNorm32(32, 640, eps=1e-05, affine=True)\n",
            "                    (1): SiLU()\n",
            "                    (2): Dropout(p=0, inplace=False)\n",
            "                    (3): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "                  )\n",
            "                  (skip_connection): Identity()\n",
            "                )\n",
            "                (1): SpatialTransformer(\n",
            "                  (norm): GroupNorm(32, 640, eps=1e-06, affine=True)\n",
            "                  (proj_in): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
            "                  (transformer_blocks): ModuleList(\n",
            "                    (0): BasicTransformerBlock(\n",
            "                      (attn1): CrossAttention(\n",
            "                        (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
            "                        (to_k): Linear(in_features=640, out_features=640, bias=False)\n",
            "                        (to_v): Linear(in_features=640, out_features=640, bias=False)\n",
            "                        (to_out): Sequential(\n",
            "                          (0): Linear(in_features=640, out_features=640, bias=True)\n",
            "                          (1): Dropout(p=0.0, inplace=False)\n",
            "                        )\n",
            "                      )\n",
            "                      (ff): FeedForward(\n",
            "                        (net): Sequential(\n",
            "                          (0): GEGLU(\n",
            "                            (proj): Linear(in_features=640, out_features=5120, bias=True)\n",
            "                          )\n",
            "                          (1): Dropout(p=0.0, inplace=False)\n",
            "                          (2): Linear(in_features=2560, out_features=640, bias=True)\n",
            "                        )\n",
            "                      )\n",
            "                      (attn2): CrossAttention(\n",
            "                        (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
            "                        (to_k): Linear(in_features=768, out_features=640, bias=False)\n",
            "                        (to_v): Linear(in_features=768, out_features=640, bias=False)\n",
            "                        (to_out): Sequential(\n",
            "                          (0): Linear(in_features=640, out_features=640, bias=True)\n",
            "                          (1): Dropout(p=0.0, inplace=False)\n",
            "                        )\n",
            "                      )\n",
            "                      (norm1): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
            "                      (norm2): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
            "                      (norm3): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
            "                    )\n",
            "                  )\n",
            "                  (proj_out): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
            "                )\n",
            "              )\n",
            "              (6): TimestepEmbedSequential(\n",
            "                (0): Downsample(\n",
            "                  (op): Conv2d(640, 640, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "                )\n",
            "              )\n",
            "              (7): TimestepEmbedSequential(\n",
            "                (0): ResBlock(\n",
            "                  (in_layers): Sequential(\n",
            "                    (0): GroupNorm32(32, 640, eps=1e-05, affine=True)\n",
            "                    (1): SiLU()\n",
            "                    (2): Conv2d(640, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "                  )\n",
            "                  (h_upd): Identity()\n",
            "                  (x_upd): Identity()\n",
            "                  (emb_layers): Sequential(\n",
            "                    (0): SiLU()\n",
            "                    (1): Linear(in_features=1280, out_features=1280, bias=True)\n",
            "                  )\n",
            "                  (out_layers): Sequential(\n",
            "                    (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
            "                    (1): SiLU()\n",
            "                    (2): Dropout(p=0, inplace=False)\n",
            "                    (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "                  )\n",
            "                  (skip_connection): Conv2d(640, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
            "                )\n",
            "                (1): SpatialTransformer(\n",
            "                  (norm): GroupNorm(32, 1280, eps=1e-06, affine=True)\n",
            "                  (proj_in): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
            "                  (transformer_blocks): ModuleList(\n",
            "                    (0): BasicTransformerBlock(\n",
            "                      (attn1): CrossAttention(\n",
            "                        (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
            "                        (to_k): Linear(in_features=1280, out_features=1280, bias=False)\n",
            "                        (to_v): Linear(in_features=1280, out_features=1280, bias=False)\n",
            "                        (to_out): Sequential(\n",
            "                          (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
            "                          (1): Dropout(p=0.0, inplace=False)\n",
            "                        )\n",
            "                      )\n",
            "                      (ff): FeedForward(\n",
            "                        (net): Sequential(\n",
            "                          (0): GEGLU(\n",
            "                            (proj): Linear(in_features=1280, out_features=10240, bias=True)\n",
            "                          )\n",
            "                          (1): Dropout(p=0.0, inplace=False)\n",
            "                          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
            "                        )\n",
            "                      )\n",
            "                      (attn2): CrossAttention(\n",
            "                        (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
            "                        (to_k): Linear(in_features=768, out_features=1280, bias=False)\n",
            "                        (to_v): Linear(in_features=768, out_features=1280, bias=False)\n",
            "                        (to_out): Sequential(\n",
            "                          (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
            "                          (1): Dropout(p=0.0, inplace=False)\n",
            "                        )\n",
            "                      )\n",
            "                      (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
            "                      (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
            "                      (norm3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
            "                    )\n",
            "                  )\n",
            "                  (proj_out): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
            "                )\n",
            "              )\n",
            "              (8): TimestepEmbedSequential(\n",
            "                (0): ResBlock(\n",
            "                  (in_layers): Sequential(\n",
            "                    (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
            "                    (1): SiLU()\n",
            "                    (2): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "                  )\n",
            "                  (h_upd): Identity()\n",
            "                  (x_upd): Identity()\n",
            "                  (emb_layers): Sequential(\n",
            "                    (0): SiLU()\n",
            "                    (1): Linear(in_features=1280, out_features=1280, bias=True)\n",
            "                  )\n",
            "                  (out_layers): Sequential(\n",
            "                    (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
            "                    (1): SiLU()\n",
            "                    (2): Dropout(p=0, inplace=False)\n",
            "                    (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "                  )\n",
            "                  (skip_connection): Identity()\n",
            "                )\n",
            "                (1): SpatialTransformer(\n",
            "                  (norm): GroupNorm(32, 1280, eps=1e-06, affine=True)\n",
            "                  (proj_in): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
            "                  (transformer_blocks): ModuleList(\n",
            "                    (0): BasicTransformerBlock(\n",
            "                      (attn1): CrossAttention(\n",
            "                        (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
            "                        (to_k): Linear(in_features=1280, out_features=1280, bias=False)\n",
            "                        (to_v): Linear(in_features=1280, out_features=1280, bias=False)\n",
            "                        (to_out): Sequential(\n",
            "                          (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
            "                          (1): Dropout(p=0.0, inplace=False)\n",
            "                        )\n",
            "                      )\n",
            "                      (ff): FeedForward(\n",
            "                        (net): Sequential(\n",
            "                          (0): GEGLU(\n",
            "                            (proj): Linear(in_features=1280, out_features=10240, bias=True)\n",
            "                          )\n",
            "                          (1): Dropout(p=0.0, inplace=False)\n",
            "                          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
            "                        )\n",
            "                      )\n",
            "                      (attn2): CrossAttention(\n",
            "                        (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
            "                        (to_k): Linear(in_features=768, out_features=1280, bias=False)\n",
            "                        (to_v): Linear(in_features=768, out_features=1280, bias=False)\n",
            "                        (to_out): Sequential(\n",
            "                          (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
            "                          (1): Dropout(p=0.0, inplace=False)\n",
            "                        )\n",
            "                      )\n",
            "                      (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
            "                      (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
            "                      (norm3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
            "                    )\n",
            "                  )\n",
            "                  (proj_out): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
            "                )\n",
            "              )\n",
            "              (9): TimestepEmbedSequential(\n",
            "                (0): Downsample(\n",
            "                  (op): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "                )\n",
            "              )\n",
            "              (10): TimestepEmbedSequential(\n",
            "                (0): ResBlock(\n",
            "                  (in_layers): Sequential(\n",
            "                    (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
            "                    (1): SiLU()\n",
            "                    (2): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "                  )\n",
            "                  (h_upd): Identity()\n",
            "                  (x_upd): Identity()\n",
            "                  (emb_layers): Sequential(\n",
            "                    (0): SiLU()\n",
            "                    (1): Linear(in_features=1280, out_features=1280, bias=True)\n",
            "                  )\n",
            "                  (out_layers): Sequential(\n",
            "                    (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
            "                    (1): SiLU()\n",
            "                    (2): Dropout(p=0, inplace=False)\n",
            "                    (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "                  )\n",
            "                  (skip_connection): Identity()\n",
            "                )\n",
            "              )\n",
            "              (11): TimestepEmbedSequential(\n",
            "                (0): ResBlock(\n",
            "                  (in_layers): Sequential(\n",
            "                    (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
            "                    (1): SiLU()\n",
            "                    (2): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "                  )\n",
            "                  (h_upd): Identity()\n",
            "                  (x_upd): Identity()\n",
            "                  (emb_layers): Sequential(\n",
            "                    (0): SiLU()\n",
            "                    (1): Linear(in_features=1280, out_features=1280, bias=True)\n",
            "                  )\n",
            "                  (out_layers): Sequential(\n",
            "                    (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
            "                    (1): SiLU()\n",
            "                    (2): Dropout(p=0, inplace=False)\n",
            "                    (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "                  )\n",
            "                  (skip_connection): Identity()\n",
            "                )\n",
            "              )\n",
            "            )\n",
            "            (middle_block): TimestepEmbedSequential(\n",
            "              (0): ResBlock(\n",
            "                (in_layers): Sequential(\n",
            "                  (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
            "                  (1): SiLU()\n",
            "                  (2): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "                )\n",
            "                (h_upd): Identity()\n",
            "                (x_upd): Identity()\n",
            "                (emb_layers): Sequential(\n",
            "                  (0): SiLU()\n",
            "                  (1): Linear(in_features=1280, out_features=1280, bias=True)\n",
            "                )\n",
            "                (out_layers): Sequential(\n",
            "                  (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
            "                  (1): SiLU()\n",
            "                  (2): Dropout(p=0, inplace=False)\n",
            "                  (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "                )\n",
            "                (skip_connection): Identity()\n",
            "              )\n",
            "              (1): SpatialTransformer(\n",
            "                (norm): GroupNorm(32, 1280, eps=1e-06, affine=True)\n",
            "                (proj_in): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
            "                (transformer_blocks): ModuleList(\n",
            "                  (0): BasicTransformerBlock(\n",
            "                    (attn1): CrossAttention(\n",
            "                      (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
            "                      (to_k): Linear(in_features=1280, out_features=1280, bias=False)\n",
            "                      (to_v): Linear(in_features=1280, out_features=1280, bias=False)\n",
            "                      (to_out): Sequential(\n",
            "                        (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
            "                        (1): Dropout(p=0.0, inplace=False)\n",
            "                      )\n",
            "                    )\n",
            "                    (ff): FeedForward(\n",
            "                      (net): Sequential(\n",
            "                        (0): GEGLU(\n",
            "                          (proj): Linear(in_features=1280, out_features=10240, bias=True)\n",
            "                        )\n",
            "                        (1): Dropout(p=0.0, inplace=False)\n",
            "                        (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
            "                      )\n",
            "                    )\n",
            "                    (attn2): CrossAttention(\n",
            "                      (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
            "                      (to_k): Linear(in_features=768, out_features=1280, bias=False)\n",
            "                      (to_v): Linear(in_features=768, out_features=1280, bias=False)\n",
            "                      (to_out): Sequential(\n",
            "                        (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
            "                        (1): Dropout(p=0.0, inplace=False)\n",
            "                      )\n",
            "                    )\n",
            "                    (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
            "                    (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
            "                    (norm3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
            "                  )\n",
            "                )\n",
            "                (proj_out): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
            "              )\n",
            "              (2): ResBlock(\n",
            "                (in_layers): Sequential(\n",
            "                  (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
            "                  (1): SiLU()\n",
            "                  (2): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "                )\n",
            "                (h_upd): Identity()\n",
            "                (x_upd): Identity()\n",
            "                (emb_layers): Sequential(\n",
            "                  (0): SiLU()\n",
            "                  (1): Linear(in_features=1280, out_features=1280, bias=True)\n",
            "                )\n",
            "                (out_layers): Sequential(\n",
            "                  (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
            "                  (1): SiLU()\n",
            "                  (2): Dropout(p=0, inplace=False)\n",
            "                  (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "                )\n",
            "                (skip_connection): Identity()\n",
            "              )\n",
            "            )\n",
            "            (output_blocks): ModuleList(\n",
            "              (0): TimestepEmbedSequential(\n",
            "                (0): ResBlock(\n",
            "                  (in_layers): Sequential(\n",
            "                    (0): GroupNorm32(32, 2560, eps=1e-05, affine=True)\n",
            "                    (1): SiLU()\n",
            "                    (2): Conv2d(2560, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "                  )\n",
            "                  (h_upd): Identity()\n",
            "                  (x_upd): Identity()\n",
            "                  (emb_layers): Sequential(\n",
            "                    (0): SiLU()\n",
            "                    (1): Linear(in_features=1280, out_features=1280, bias=True)\n",
            "                  )\n",
            "                  (out_layers): Sequential(\n",
            "                    (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
            "                    (1): SiLU()\n",
            "                    (2): Dropout(p=0, inplace=False)\n",
            "                    (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "                  )\n",
            "                  (skip_connection): Conv2d(2560, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
            "                )\n",
            "              )\n",
            "              (1): TimestepEmbedSequential(\n",
            "                (0): ResBlock(\n",
            "                  (in_layers): Sequential(\n",
            "                    (0): GroupNorm32(32, 2560, eps=1e-05, affine=True)\n",
            "                    (1): SiLU()\n",
            "                    (2): Conv2d(2560, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "                  )\n",
            "                  (h_upd): Identity()\n",
            "                  (x_upd): Identity()\n",
            "                  (emb_layers): Sequential(\n",
            "                    (0): SiLU()\n",
            "                    (1): Linear(in_features=1280, out_features=1280, bias=True)\n",
            "                  )\n",
            "                  (out_layers): Sequential(\n",
            "                    (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
            "                    (1): SiLU()\n",
            "                    (2): Dropout(p=0, inplace=False)\n",
            "                    (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "                  )\n",
            "                  (skip_connection): Conv2d(2560, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
            "                )\n",
            "              )\n",
            "              (2): TimestepEmbedSequential(\n",
            "                (0): ResBlock(\n",
            "                  (in_layers): Sequential(\n",
            "                    (0): GroupNorm32(32, 2560, eps=1e-05, affine=True)\n",
            "                    (1): SiLU()\n",
            "                    (2): Conv2d(2560, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "                  )\n",
            "                  (h_upd): Identity()\n",
            "                  (x_upd): Identity()\n",
            "                  (emb_layers): Sequential(\n",
            "                    (0): SiLU()\n",
            "                    (1): Linear(in_features=1280, out_features=1280, bias=True)\n",
            "                  )\n",
            "                  (out_layers): Sequential(\n",
            "                    (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
            "                    (1): SiLU()\n",
            "                    (2): Dropout(p=0, inplace=False)\n",
            "                    (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "                  )\n",
            "                  (skip_connection): Conv2d(2560, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
            "                )\n",
            "                (1): Upsample(\n",
            "                  (conv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "                )\n",
            "              )\n",
            "              (3): TimestepEmbedSequential(\n",
            "                (0): ResBlock(\n",
            "                  (in_layers): Sequential(\n",
            "                    (0): GroupNorm32(32, 2560, eps=1e-05, affine=True)\n",
            "                    (1): SiLU()\n",
            "                    (2): Conv2d(2560, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "                  )\n",
            "                  (h_upd): Identity()\n",
            "                  (x_upd): Identity()\n",
            "                  (emb_layers): Sequential(\n",
            "                    (0): SiLU()\n",
            "                    (1): Linear(in_features=1280, out_features=1280, bias=True)\n",
            "                  )\n",
            "                  (out_layers): Sequential(\n",
            "                    (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
            "                    (1): SiLU()\n",
            "                    (2): Dropout(p=0, inplace=False)\n",
            "                    (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "                  )\n",
            "                  (skip_connection): Conv2d(2560, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
            "                )\n",
            "                (1): SpatialTransformer(\n",
            "                  (norm): GroupNorm(32, 1280, eps=1e-06, affine=True)\n",
            "                  (proj_in): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
            "                  (transformer_blocks): ModuleList(\n",
            "                    (0): BasicTransformerBlock(\n",
            "                      (attn1): CrossAttention(\n",
            "                        (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
            "                        (to_k): Linear(in_features=1280, out_features=1280, bias=False)\n",
            "                        (to_v): Linear(in_features=1280, out_features=1280, bias=False)\n",
            "                        (to_out): Sequential(\n",
            "                          (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
            "                          (1): Dropout(p=0.0, inplace=False)\n",
            "                        )\n",
            "                      )\n",
            "                      (ff): FeedForward(\n",
            "                        (net): Sequential(\n",
            "                          (0): GEGLU(\n",
            "                            (proj): Linear(in_features=1280, out_features=10240, bias=True)\n",
            "                          )\n",
            "                          (1): Dropout(p=0.0, inplace=False)\n",
            "                          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
            "                        )\n",
            "                      )\n",
            "                      (attn2): CrossAttention(\n",
            "                        (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
            "                        (to_k): Linear(in_features=768, out_features=1280, bias=False)\n",
            "                        (to_v): Linear(in_features=768, out_features=1280, bias=False)\n",
            "                        (to_out): Sequential(\n",
            "                          (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
            "                          (1): Dropout(p=0.0, inplace=False)\n",
            "                        )\n",
            "                      )\n",
            "                      (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
            "                      (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
            "                      (norm3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
            "                    )\n",
            "                  )\n",
            "                  (proj_out): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
            "                )\n",
            "              )\n",
            "              (4): TimestepEmbedSequential(\n",
            "                (0): ResBlock(\n",
            "                  (in_layers): Sequential(\n",
            "                    (0): GroupNorm32(32, 2560, eps=1e-05, affine=True)\n",
            "                    (1): SiLU()\n",
            "                    (2): Conv2d(2560, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "                  )\n",
            "                  (h_upd): Identity()\n",
            "                  (x_upd): Identity()\n",
            "                  (emb_layers): Sequential(\n",
            "                    (0): SiLU()\n",
            "                    (1): Linear(in_features=1280, out_features=1280, bias=True)\n",
            "                  )\n",
            "                  (out_layers): Sequential(\n",
            "                    (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
            "                    (1): SiLU()\n",
            "                    (2): Dropout(p=0, inplace=False)\n",
            "                    (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "                  )\n",
            "                  (skip_connection): Conv2d(2560, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
            "                )\n",
            "                (1): SpatialTransformer(\n",
            "                  (norm): GroupNorm(32, 1280, eps=1e-06, affine=True)\n",
            "                  (proj_in): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
            "                  (transformer_blocks): ModuleList(\n",
            "                    (0): BasicTransformerBlock(\n",
            "                      (attn1): CrossAttention(\n",
            "                        (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
            "                        (to_k): Linear(in_features=1280, out_features=1280, bias=False)\n",
            "                        (to_v): Linear(in_features=1280, out_features=1280, bias=False)\n",
            "                        (to_out): Sequential(\n",
            "                          (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
            "                          (1): Dropout(p=0.0, inplace=False)\n",
            "                        )\n",
            "                      )\n",
            "                      (ff): FeedForward(\n",
            "                        (net): Sequential(\n",
            "                          (0): GEGLU(\n",
            "                            (proj): Linear(in_features=1280, out_features=10240, bias=True)\n",
            "                          )\n",
            "                          (1): Dropout(p=0.0, inplace=False)\n",
            "                          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
            "                        )\n",
            "                      )\n",
            "                      (attn2): CrossAttention(\n",
            "                        (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
            "                        (to_k): Linear(in_features=768, out_features=1280, bias=False)\n",
            "                        (to_v): Linear(in_features=768, out_features=1280, bias=False)\n",
            "                        (to_out): Sequential(\n",
            "                          (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
            "                          (1): Dropout(p=0.0, inplace=False)\n",
            "                        )\n",
            "                      )\n",
            "                      (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
            "                      (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
            "                      (norm3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
            "                    )\n",
            "                  )\n",
            "                  (proj_out): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
            "                )\n",
            "              )\n",
            "              (5): TimestepEmbedSequential(\n",
            "                (0): ResBlock(\n",
            "                  (in_layers): Sequential(\n",
            "                    (0): GroupNorm32(32, 1920, eps=1e-05, affine=True)\n",
            "                    (1): SiLU()\n",
            "                    (2): Conv2d(1920, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "                  )\n",
            "                  (h_upd): Identity()\n",
            "                  (x_upd): Identity()\n",
            "                  (emb_layers): Sequential(\n",
            "                    (0): SiLU()\n",
            "                    (1): Linear(in_features=1280, out_features=1280, bias=True)\n",
            "                  )\n",
            "                  (out_layers): Sequential(\n",
            "                    (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
            "                    (1): SiLU()\n",
            "                    (2): Dropout(p=0, inplace=False)\n",
            "                    (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "                  )\n",
            "                  (skip_connection): Conv2d(1920, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
            "                )\n",
            "                (1): SpatialTransformer(\n",
            "                  (norm): GroupNorm(32, 1280, eps=1e-06, affine=True)\n",
            "                  (proj_in): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
            "                  (transformer_blocks): ModuleList(\n",
            "                    (0): BasicTransformerBlock(\n",
            "                      (attn1): CrossAttention(\n",
            "                        (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
            "                        (to_k): Linear(in_features=1280, out_features=1280, bias=False)\n",
            "                        (to_v): Linear(in_features=1280, out_features=1280, bias=False)\n",
            "                        (to_out): Sequential(\n",
            "                          (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
            "                          (1): Dropout(p=0.0, inplace=False)\n",
            "                        )\n",
            "                      )\n",
            "                      (ff): FeedForward(\n",
            "                        (net): Sequential(\n",
            "                          (0): GEGLU(\n",
            "                            (proj): Linear(in_features=1280, out_features=10240, bias=True)\n",
            "                          )\n",
            "                          (1): Dropout(p=0.0, inplace=False)\n",
            "                          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
            "                        )\n",
            "                      )\n",
            "                      (attn2): CrossAttention(\n",
            "                        (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
            "                        (to_k): Linear(in_features=768, out_features=1280, bias=False)\n",
            "                        (to_v): Linear(in_features=768, out_features=1280, bias=False)\n",
            "                        (to_out): Sequential(\n",
            "                          (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
            "                          (1): Dropout(p=0.0, inplace=False)\n",
            "                        )\n",
            "                      )\n",
            "                      (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
            "                      (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
            "                      (norm3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
            "                    )\n",
            "                  )\n",
            "                  (proj_out): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
            "                )\n",
            "                (2): Upsample(\n",
            "                  (conv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "                )\n",
            "              )\n",
            "              (6): TimestepEmbedSequential(\n",
            "                (0): ResBlock(\n",
            "                  (in_layers): Sequential(\n",
            "                    (0): GroupNorm32(32, 1920, eps=1e-05, affine=True)\n",
            "                    (1): SiLU()\n",
            "                    (2): Conv2d(1920, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "                  )\n",
            "                  (h_upd): Identity()\n",
            "                  (x_upd): Identity()\n",
            "                  (emb_layers): Sequential(\n",
            "                    (0): SiLU()\n",
            "                    (1): Linear(in_features=1280, out_features=640, bias=True)\n",
            "                  )\n",
            "                  (out_layers): Sequential(\n",
            "                    (0): GroupNorm32(32, 640, eps=1e-05, affine=True)\n",
            "                    (1): SiLU()\n",
            "                    (2): Dropout(p=0, inplace=False)\n",
            "                    (3): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "                  )\n",
            "                  (skip_connection): Conv2d(1920, 640, kernel_size=(1, 1), stride=(1, 1))\n",
            "                )\n",
            "                (1): SpatialTransformer(\n",
            "                  (norm): GroupNorm(32, 640, eps=1e-06, affine=True)\n",
            "                  (proj_in): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
            "                  (transformer_blocks): ModuleList(\n",
            "                    (0): BasicTransformerBlock(\n",
            "                      (attn1): CrossAttention(\n",
            "                        (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
            "                        (to_k): Linear(in_features=640, out_features=640, bias=False)\n",
            "                        (to_v): Linear(in_features=640, out_features=640, bias=False)\n",
            "                        (to_out): Sequential(\n",
            "                          (0): Linear(in_features=640, out_features=640, bias=True)\n",
            "                          (1): Dropout(p=0.0, inplace=False)\n",
            "                        )\n",
            "                      )\n",
            "                      (ff): FeedForward(\n",
            "                        (net): Sequential(\n",
            "                          (0): GEGLU(\n",
            "                            (proj): Linear(in_features=640, out_features=5120, bias=True)\n",
            "                          )\n",
            "                          (1): Dropout(p=0.0, inplace=False)\n",
            "                          (2): Linear(in_features=2560, out_features=640, bias=True)\n",
            "                        )\n",
            "                      )\n",
            "                      (attn2): CrossAttention(\n",
            "                        (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
            "                        (to_k): Linear(in_features=768, out_features=640, bias=False)\n",
            "                        (to_v): Linear(in_features=768, out_features=640, bias=False)\n",
            "                        (to_out): Sequential(\n",
            "                          (0): Linear(in_features=640, out_features=640, bias=True)\n",
            "                          (1): Dropout(p=0.0, inplace=False)\n",
            "                        )\n",
            "                      )\n",
            "                      (norm1): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
            "                      (norm2): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
            "                      (norm3): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
            "                    )\n",
            "                  )\n",
            "                  (proj_out): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
            "                )\n",
            "              )\n",
            "              (7): TimestepEmbedSequential(\n",
            "                (0): ResBlock(\n",
            "                  (in_layers): Sequential(\n",
            "                    (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
            "                    (1): SiLU()\n",
            "                    (2): Conv2d(1280, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "                  )\n",
            "                  (h_upd): Identity()\n",
            "                  (x_upd): Identity()\n",
            "                  (emb_layers): Sequential(\n",
            "                    (0): SiLU()\n",
            "                    (1): Linear(in_features=1280, out_features=640, bias=True)\n",
            "                  )\n",
            "                  (out_layers): Sequential(\n",
            "                    (0): GroupNorm32(32, 640, eps=1e-05, affine=True)\n",
            "                    (1): SiLU()\n",
            "                    (2): Dropout(p=0, inplace=False)\n",
            "                    (3): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "                  )\n",
            "                  (skip_connection): Conv2d(1280, 640, kernel_size=(1, 1), stride=(1, 1))\n",
            "                )\n",
            "                (1): SpatialTransformer(\n",
            "                  (norm): GroupNorm(32, 640, eps=1e-06, affine=True)\n",
            "                  (proj_in): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
            "                  (transformer_blocks): ModuleList(\n",
            "                    (0): BasicTransformerBlock(\n",
            "                      (attn1): CrossAttention(\n",
            "                        (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
            "                        (to_k): Linear(in_features=640, out_features=640, bias=False)\n",
            "                        (to_v): Linear(in_features=640, out_features=640, bias=False)\n",
            "                        (to_out): Sequential(\n",
            "                          (0): Linear(in_features=640, out_features=640, bias=True)\n",
            "                          (1): Dropout(p=0.0, inplace=False)\n",
            "                        )\n",
            "                      )\n",
            "                      (ff): FeedForward(\n",
            "                        (net): Sequential(\n",
            "                          (0): GEGLU(\n",
            "                            (proj): Linear(in_features=640, out_features=5120, bias=True)\n",
            "                          )\n",
            "                          (1): Dropout(p=0.0, inplace=False)\n",
            "                          (2): Linear(in_features=2560, out_features=640, bias=True)\n",
            "                        )\n",
            "                      )\n",
            "                      (attn2): CrossAttention(\n",
            "                        (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
            "                        (to_k): Linear(in_features=768, out_features=640, bias=False)\n",
            "                        (to_v): Linear(in_features=768, out_features=640, bias=False)\n",
            "                        (to_out): Sequential(\n",
            "                          (0): Linear(in_features=640, out_features=640, bias=True)\n",
            "                          (1): Dropout(p=0.0, inplace=False)\n",
            "                        )\n",
            "                      )\n",
            "                      (norm1): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
            "                      (norm2): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
            "                      (norm3): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
            "                    )\n",
            "                  )\n",
            "                  (proj_out): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
            "                )\n",
            "              )\n",
            "              (8): TimestepEmbedSequential(\n",
            "                (0): ResBlock(\n",
            "                  (in_layers): Sequential(\n",
            "                    (0): GroupNorm32(32, 960, eps=1e-05, affine=True)\n",
            "                    (1): SiLU()\n",
            "                    (2): Conv2d(960, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "                  )\n",
            "                  (h_upd): Identity()\n",
            "                  (x_upd): Identity()\n",
            "                  (emb_layers): Sequential(\n",
            "                    (0): SiLU()\n",
            "                    (1): Linear(in_features=1280, out_features=640, bias=True)\n",
            "                  )\n",
            "                  (out_layers): Sequential(\n",
            "                    (0): GroupNorm32(32, 640, eps=1e-05, affine=True)\n",
            "                    (1): SiLU()\n",
            "                    (2): Dropout(p=0, inplace=False)\n",
            "                    (3): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "                  )\n",
            "                  (skip_connection): Conv2d(960, 640, kernel_size=(1, 1), stride=(1, 1))\n",
            "                )\n",
            "                (1): SpatialTransformer(\n",
            "                  (norm): GroupNorm(32, 640, eps=1e-06, affine=True)\n",
            "                  (proj_in): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
            "                  (transformer_blocks): ModuleList(\n",
            "                    (0): BasicTransformerBlock(\n",
            "                      (attn1): CrossAttention(\n",
            "                        (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
            "                        (to_k): Linear(in_features=640, out_features=640, bias=False)\n",
            "                        (to_v): Linear(in_features=640, out_features=640, bias=False)\n",
            "                        (to_out): Sequential(\n",
            "                          (0): Linear(in_features=640, out_features=640, bias=True)\n",
            "                          (1): Dropout(p=0.0, inplace=False)\n",
            "                        )\n",
            "                      )\n",
            "                      (ff): FeedForward(\n",
            "                        (net): Sequential(\n",
            "                          (0): GEGLU(\n",
            "                            (proj): Linear(in_features=640, out_features=5120, bias=True)\n",
            "                          )\n",
            "                          (1): Dropout(p=0.0, inplace=False)\n",
            "                          (2): Linear(in_features=2560, out_features=640, bias=True)\n",
            "                        )\n",
            "                      )\n",
            "                      (attn2): CrossAttention(\n",
            "                        (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
            "                        (to_k): Linear(in_features=768, out_features=640, bias=False)\n",
            "                        (to_v): Linear(in_features=768, out_features=640, bias=False)\n",
            "                        (to_out): Sequential(\n",
            "                          (0): Linear(in_features=640, out_features=640, bias=True)\n",
            "                          (1): Dropout(p=0.0, inplace=False)\n",
            "                        )\n",
            "                      )\n",
            "                      (norm1): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
            "                      (norm2): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
            "                      (norm3): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
            "                    )\n",
            "                  )\n",
            "                  (proj_out): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
            "                )\n",
            "                (2): Upsample(\n",
            "                  (conv): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "                )\n",
            "              )\n",
            "              (9): TimestepEmbedSequential(\n",
            "                (0): ResBlock(\n",
            "                  (in_layers): Sequential(\n",
            "                    (0): GroupNorm32(32, 960, eps=1e-05, affine=True)\n",
            "                    (1): SiLU()\n",
            "                    (2): Conv2d(960, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "                  )\n",
            "                  (h_upd): Identity()\n",
            "                  (x_upd): Identity()\n",
            "                  (emb_layers): Sequential(\n",
            "                    (0): SiLU()\n",
            "                    (1): Linear(in_features=1280, out_features=320, bias=True)\n",
            "                  )\n",
            "                  (out_layers): Sequential(\n",
            "                    (0): GroupNorm32(32, 320, eps=1e-05, affine=True)\n",
            "                    (1): SiLU()\n",
            "                    (2): Dropout(p=0, inplace=False)\n",
            "                    (3): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "                  )\n",
            "                  (skip_connection): Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1))\n",
            "                )\n",
            "                (1): SpatialTransformer(\n",
            "                  (norm): GroupNorm(32, 320, eps=1e-06, affine=True)\n",
            "                  (proj_in): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
            "                  (transformer_blocks): ModuleList(\n",
            "                    (0): BasicTransformerBlock(\n",
            "                      (attn1): CrossAttention(\n",
            "                        (to_q): Linear(in_features=320, out_features=320, bias=False)\n",
            "                        (to_k): Linear(in_features=320, out_features=320, bias=False)\n",
            "                        (to_v): Linear(in_features=320, out_features=320, bias=False)\n",
            "                        (to_out): Sequential(\n",
            "                          (0): Linear(in_features=320, out_features=320, bias=True)\n",
            "                          (1): Dropout(p=0.0, inplace=False)\n",
            "                        )\n",
            "                      )\n",
            "                      (ff): FeedForward(\n",
            "                        (net): Sequential(\n",
            "                          (0): GEGLU(\n",
            "                            (proj): Linear(in_features=320, out_features=2560, bias=True)\n",
            "                          )\n",
            "                          (1): Dropout(p=0.0, inplace=False)\n",
            "                          (2): Linear(in_features=1280, out_features=320, bias=True)\n",
            "                        )\n",
            "                      )\n",
            "                      (attn2): CrossAttention(\n",
            "                        (to_q): Linear(in_features=320, out_features=320, bias=False)\n",
            "                        (to_k): Linear(in_features=768, out_features=320, bias=False)\n",
            "                        (to_v): Linear(in_features=768, out_features=320, bias=False)\n",
            "                        (to_out): Sequential(\n",
            "                          (0): Linear(in_features=320, out_features=320, bias=True)\n",
            "                          (1): Dropout(p=0.0, inplace=False)\n",
            "                        )\n",
            "                      )\n",
            "                      (norm1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
            "                      (norm2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
            "                      (norm3): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
            "                    )\n",
            "                  )\n",
            "                  (proj_out): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
            "                )\n",
            "              )\n",
            "              (10): TimestepEmbedSequential(\n",
            "                (0): ResBlock(\n",
            "                  (in_layers): Sequential(\n",
            "                    (0): GroupNorm32(32, 640, eps=1e-05, affine=True)\n",
            "                    (1): SiLU()\n",
            "                    (2): Conv2d(640, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "                  )\n",
            "                  (h_upd): Identity()\n",
            "                  (x_upd): Identity()\n",
            "                  (emb_layers): Sequential(\n",
            "                    (0): SiLU()\n",
            "                    (1): Linear(in_features=1280, out_features=320, bias=True)\n",
            "                  )\n",
            "                  (out_layers): Sequential(\n",
            "                    (0): GroupNorm32(32, 320, eps=1e-05, affine=True)\n",
            "                    (1): SiLU()\n",
            "                    (2): Dropout(p=0, inplace=False)\n",
            "                    (3): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "                  )\n",
            "                  (skip_connection): Conv2d(640, 320, kernel_size=(1, 1), stride=(1, 1))\n",
            "                )\n",
            "                (1): SpatialTransformer(\n",
            "                  (norm): GroupNorm(32, 320, eps=1e-06, affine=True)\n",
            "                  (proj_in): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
            "                  (transformer_blocks): ModuleList(\n",
            "                    (0): BasicTransformerBlock(\n",
            "                      (attn1): CrossAttention(\n",
            "                        (to_q): Linear(in_features=320, out_features=320, bias=False)\n",
            "                        (to_k): Linear(in_features=320, out_features=320, bias=False)\n",
            "                        (to_v): Linear(in_features=320, out_features=320, bias=False)\n",
            "                        (to_out): Sequential(\n",
            "                          (0): Linear(in_features=320, out_features=320, bias=True)\n",
            "                          (1): Dropout(p=0.0, inplace=False)\n",
            "                        )\n",
            "                      )\n",
            "                      (ff): FeedForward(\n",
            "                        (net): Sequential(\n",
            "                          (0): GEGLU(\n",
            "                            (proj): Linear(in_features=320, out_features=2560, bias=True)\n",
            "                          )\n",
            "                          (1): Dropout(p=0.0, inplace=False)\n",
            "                          (2): Linear(in_features=1280, out_features=320, bias=True)\n",
            "                        )\n",
            "                      )\n",
            "                      (attn2): CrossAttention(\n",
            "                        (to_q): Linear(in_features=320, out_features=320, bias=False)\n",
            "                        (to_k): Linear(in_features=768, out_features=320, bias=False)\n",
            "                        (to_v): Linear(in_features=768, out_features=320, bias=False)\n",
            "                        (to_out): Sequential(\n",
            "                          (0): Linear(in_features=320, out_features=320, bias=True)\n",
            "                          (1): Dropout(p=0.0, inplace=False)\n",
            "                        )\n",
            "                      )\n",
            "                      (norm1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
            "                      (norm2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
            "                      (norm3): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
            "                    )\n",
            "                  )\n",
            "                  (proj_out): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
            "                )\n",
            "              )\n",
            "              (11): TimestepEmbedSequential(\n",
            "                (0): ResBlock(\n",
            "                  (in_layers): Sequential(\n",
            "                    (0): GroupNorm32(32, 640, eps=1e-05, affine=True)\n",
            "                    (1): SiLU()\n",
            "                    (2): Conv2d(640, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "                  )\n",
            "                  (h_upd): Identity()\n",
            "                  (x_upd): Identity()\n",
            "                  (emb_layers): Sequential(\n",
            "                    (0): SiLU()\n",
            "                    (1): Linear(in_features=1280, out_features=320, bias=True)\n",
            "                  )\n",
            "                  (out_layers): Sequential(\n",
            "                    (0): GroupNorm32(32, 320, eps=1e-05, affine=True)\n",
            "                    (1): SiLU()\n",
            "                    (2): Dropout(p=0, inplace=False)\n",
            "                    (3): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "                  )\n",
            "                  (skip_connection): Conv2d(640, 320, kernel_size=(1, 1), stride=(1, 1))\n",
            "                )\n",
            "                (1): SpatialTransformer(\n",
            "                  (norm): GroupNorm(32, 320, eps=1e-06, affine=True)\n",
            "                  (proj_in): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
            "                  (transformer_blocks): ModuleList(\n",
            "                    (0): BasicTransformerBlock(\n",
            "                      (attn1): CrossAttention(\n",
            "                        (to_q): Linear(in_features=320, out_features=320, bias=False)\n",
            "                        (to_k): Linear(in_features=320, out_features=320, bias=False)\n",
            "                        (to_v): Linear(in_features=320, out_features=320, bias=False)\n",
            "                        (to_out): Sequential(\n",
            "                          (0): Linear(in_features=320, out_features=320, bias=True)\n",
            "                          (1): Dropout(p=0.0, inplace=False)\n",
            "                        )\n",
            "                      )\n",
            "                      (ff): FeedForward(\n",
            "                        (net): Sequential(\n",
            "                          (0): GEGLU(\n",
            "                            (proj): Linear(in_features=320, out_features=2560, bias=True)\n",
            "                          )\n",
            "                          (1): Dropout(p=0.0, inplace=False)\n",
            "                          (2): Linear(in_features=1280, out_features=320, bias=True)\n",
            "                        )\n",
            "                      )\n",
            "                      (attn2): CrossAttention(\n",
            "                        (to_q): Linear(in_features=320, out_features=320, bias=False)\n",
            "                        (to_k): Linear(in_features=768, out_features=320, bias=False)\n",
            "                        (to_v): Linear(in_features=768, out_features=320, bias=False)\n",
            "                        (to_out): Sequential(\n",
            "                          (0): Linear(in_features=320, out_features=320, bias=True)\n",
            "                          (1): Dropout(p=0.0, inplace=False)\n",
            "                        )\n",
            "                      )\n",
            "                      (norm1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
            "                      (norm2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
            "                      (norm3): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
            "                    )\n",
            "                  )\n",
            "                  (proj_out): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
            "                )\n",
            "              )\n",
            "            )\n",
            "            (out): Sequential(\n",
            "              (0): GroupNorm32(32, 320, eps=1e-05, affine=True)\n",
            "              (1): SiLU()\n",
            "              (2): Conv2d(320, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (first_stage_model): AutoencoderKL(\n",
            "          (encoder): Encoder(\n",
            "            (conv_in): Conv2d(3, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            (down): ModuleList(\n",
            "              (0): Module(\n",
            "                (block): ModuleList(\n",
            "                  (0): ResnetBlock(\n",
            "                    (norm1): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
            "                    (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "                    (norm2): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
            "                    (dropout): Dropout(p=0.0, inplace=False)\n",
            "                    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "                  )\n",
            "                  (1): ResnetBlock(\n",
            "                    (norm1): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
            "                    (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "                    (norm2): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
            "                    (dropout): Dropout(p=0.0, inplace=False)\n",
            "                    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "                  )\n",
            "                )\n",
            "                (attn): ModuleList()\n",
            "                (downsample): Downsample(\n",
            "                  (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2))\n",
            "                )\n",
            "              )\n",
            "              (1): Module(\n",
            "                (block): ModuleList(\n",
            "                  (0): ResnetBlock(\n",
            "                    (norm1): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
            "                    (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "                    (norm2): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
            "                    (dropout): Dropout(p=0.0, inplace=False)\n",
            "                    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "                    (nin_shortcut): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "                  )\n",
            "                  (1): ResnetBlock(\n",
            "                    (norm1): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
            "                    (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "                    (norm2): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
            "                    (dropout): Dropout(p=0.0, inplace=False)\n",
            "                    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "                  )\n",
            "                )\n",
            "                (attn): ModuleList()\n",
            "                (downsample): Downsample(\n",
            "                  (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2))\n",
            "                )\n",
            "              )\n",
            "              (2): Module(\n",
            "                (block): ModuleList(\n",
            "                  (0): ResnetBlock(\n",
            "                    (norm1): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
            "                    (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "                    (norm2): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
            "                    (dropout): Dropout(p=0.0, inplace=False)\n",
            "                    (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "                    (nin_shortcut): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "                  )\n",
            "                  (1): ResnetBlock(\n",
            "                    (norm1): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
            "                    (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "                    (norm2): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
            "                    (dropout): Dropout(p=0.0, inplace=False)\n",
            "                    (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "                  )\n",
            "                )\n",
            "                (attn): ModuleList()\n",
            "                (downsample): Downsample(\n",
            "                  (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2))\n",
            "                )\n",
            "              )\n",
            "              (3): Module(\n",
            "                (block): ModuleList(\n",
            "                  (0): ResnetBlock(\n",
            "                    (norm1): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
            "                    (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "                    (norm2): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
            "                    (dropout): Dropout(p=0.0, inplace=False)\n",
            "                    (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "                  )\n",
            "                  (1): ResnetBlock(\n",
            "                    (norm1): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
            "                    (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "                    (norm2): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
            "                    (dropout): Dropout(p=0.0, inplace=False)\n",
            "                    (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "                  )\n",
            "                )\n",
            "                (attn): ModuleList()\n",
            "              )\n",
            "            )\n",
            "            (mid): Module(\n",
            "              (block_1): ResnetBlock(\n",
            "                (norm1): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
            "                (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "                (norm2): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
            "                (dropout): Dropout(p=0.0, inplace=False)\n",
            "                (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "              )\n",
            "              (attn_1): AttnBlock(\n",
            "                (norm): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
            "                (q): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "                (k): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "                (v): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "                (proj_out): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "              )\n",
            "              (block_2): ResnetBlock(\n",
            "                (norm1): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
            "                (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "                (norm2): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
            "                (dropout): Dropout(p=0.0, inplace=False)\n",
            "                (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "              )\n",
            "            )\n",
            "            (norm_out): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
            "            (conv_out): Conv2d(512, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          )\n",
            "          (decoder): Decoder(\n",
            "            (conv_in): Conv2d(4, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            (mid): Module(\n",
            "              (block_1): ResnetBlock(\n",
            "                (norm1): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
            "                (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "                (norm2): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
            "                (dropout): Dropout(p=0.0, inplace=False)\n",
            "                (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "              )\n",
            "              (attn_1): AttnBlock(\n",
            "                (norm): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
            "                (q): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "                (k): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "                (v): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "                (proj_out): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "              )\n",
            "              (block_2): ResnetBlock(\n",
            "                (norm1): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
            "                (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "                (norm2): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
            "                (dropout): Dropout(p=0.0, inplace=False)\n",
            "                (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "              )\n",
            "            )\n",
            "            (up): ModuleList(\n",
            "              (0): Module(\n",
            "                (block): ModuleList(\n",
            "                  (0): ResnetBlock(\n",
            "                    (norm1): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
            "                    (conv1): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "                    (norm2): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
            "                    (dropout): Dropout(p=0.0, inplace=False)\n",
            "                    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "                    (nin_shortcut): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "                  )\n",
            "                  (1): ResnetBlock(\n",
            "                    (norm1): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
            "                    (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "                    (norm2): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
            "                    (dropout): Dropout(p=0.0, inplace=False)\n",
            "                    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "                  )\n",
            "                  (2): ResnetBlock(\n",
            "                    (norm1): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
            "                    (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "                    (norm2): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
            "                    (dropout): Dropout(p=0.0, inplace=False)\n",
            "                    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "                  )\n",
            "                )\n",
            "                (attn): ModuleList()\n",
            "              )\n",
            "              (1): Module(\n",
            "                (block): ModuleList(\n",
            "                  (0): ResnetBlock(\n",
            "                    (norm1): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
            "                    (conv1): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "                    (norm2): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
            "                    (dropout): Dropout(p=0.0, inplace=False)\n",
            "                    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "                    (nin_shortcut): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "                  )\n",
            "                  (1): ResnetBlock(\n",
            "                    (norm1): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
            "                    (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "                    (norm2): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
            "                    (dropout): Dropout(p=0.0, inplace=False)\n",
            "                    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "                  )\n",
            "                  (2): ResnetBlock(\n",
            "                    (norm1): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
            "                    (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "                    (norm2): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
            "                    (dropout): Dropout(p=0.0, inplace=False)\n",
            "                    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "                  )\n",
            "                )\n",
            "                (attn): ModuleList()\n",
            "                (upsample): Upsample(\n",
            "                  (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "                )\n",
            "              )\n",
            "              (2): Module(\n",
            "                (block): ModuleList(\n",
            "                  (0): ResnetBlock(\n",
            "                    (norm1): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
            "                    (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "                    (norm2): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
            "                    (dropout): Dropout(p=0.0, inplace=False)\n",
            "                    (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "                  )\n",
            "                  (1): ResnetBlock(\n",
            "                    (norm1): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
            "                    (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "                    (norm2): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
            "                    (dropout): Dropout(p=0.0, inplace=False)\n",
            "                    (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "                  )\n",
            "                  (2): ResnetBlock(\n",
            "                    (norm1): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
            "                    (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "                    (norm2): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
            "                    (dropout): Dropout(p=0.0, inplace=False)\n",
            "                    (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "                  )\n",
            "                )\n",
            "                (attn): ModuleList()\n",
            "                (upsample): Upsample(\n",
            "                  (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "                )\n",
            "              )\n",
            "              (3): Module(\n",
            "                (block): ModuleList(\n",
            "                  (0): ResnetBlock(\n",
            "                    (norm1): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
            "                    (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "                    (norm2): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
            "                    (dropout): Dropout(p=0.0, inplace=False)\n",
            "                    (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "                  )\n",
            "                  (1): ResnetBlock(\n",
            "                    (norm1): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
            "                    (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "                    (norm2): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
            "                    (dropout): Dropout(p=0.0, inplace=False)\n",
            "                    (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "                  )\n",
            "                  (2): ResnetBlock(\n",
            "                    (norm1): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
            "                    (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "                    (norm2): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
            "                    (dropout): Dropout(p=0.0, inplace=False)\n",
            "                    (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "                  )\n",
            "                )\n",
            "                (attn): ModuleList()\n",
            "                (upsample): Upsample(\n",
            "                  (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "                )\n",
            "              )\n",
            "            )\n",
            "            (norm_out): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
            "            (conv_out): Conv2d(128, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          )\n",
            "          (loss): Identity()\n",
            "          (quant_conv): Conv2d(8, 8, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (post_quant_conv): Conv2d(4, 4, kernel_size=(1, 1), stride=(1, 1))\n",
            "        )\n",
            "        (cond_stage_model): FrozenCLIPEmbedder(\n",
            "          (transformer): CLIPTextModel(\n",
            "            (text_model): CLIPTextTransformer(\n",
            "              (embeddings): CLIPTextEmbeddings(\n",
            "                (token_embedding): Embedding(49408, 768)\n",
            "                (position_embedding): Embedding(77, 768)\n",
            "              )\n",
            "              (encoder): CLIPEncoder(\n",
            "                (layers): ModuleList(\n",
            "                  (0): CLIPEncoderLayer(\n",
            "                    (self_attn): CLIPAttention(\n",
            "                      (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "                      (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "                      (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "                      (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    )\n",
            "                    (layer_norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                    (mlp): CLIPMLP(\n",
            "                      (activation_fn): QuickGELUActivation()\n",
            "                      (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                      (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                    )\n",
            "                    (layer_norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                  )\n",
            "                  (1): CLIPEncoderLayer(\n",
            "                    (self_attn): CLIPAttention(\n",
            "                      (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "                      (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "                      (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "                      (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    )\n",
            "                    (layer_norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                    (mlp): CLIPMLP(\n",
            "                      (activation_fn): QuickGELUActivation()\n",
            "                      (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                      (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                    )\n",
            "                    (layer_norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                  )\n",
            "                  (2): CLIPEncoderLayer(\n",
            "                    (self_attn): CLIPAttention(\n",
            "                      (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "                      (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "                      (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "                      (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    )\n",
            "                    (layer_norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                    (mlp): CLIPMLP(\n",
            "                      (activation_fn): QuickGELUActivation()\n",
            "                      (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                      (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                    )\n",
            "                    (layer_norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                  )\n",
            "                  (3): CLIPEncoderLayer(\n",
            "                    (self_attn): CLIPAttention(\n",
            "                      (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "                      (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "                      (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "                      (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    )\n",
            "                    (layer_norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                    (mlp): CLIPMLP(\n",
            "                      (activation_fn): QuickGELUActivation()\n",
            "                      (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                      (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                    )\n",
            "                    (layer_norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                  )\n",
            "                  (4): CLIPEncoderLayer(\n",
            "                    (self_attn): CLIPAttention(\n",
            "                      (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "                      (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "                      (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "                      (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    )\n",
            "                    (layer_norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                    (mlp): CLIPMLP(\n",
            "                      (activation_fn): QuickGELUActivation()\n",
            "                      (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                      (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                    )\n",
            "                    (layer_norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                  )\n",
            "                  (5): CLIPEncoderLayer(\n",
            "                    (self_attn): CLIPAttention(\n",
            "                      (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "                      (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "                      (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "                      (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    )\n",
            "                    (layer_norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                    (mlp): CLIPMLP(\n",
            "                      (activation_fn): QuickGELUActivation()\n",
            "                      (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                      (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                    )\n",
            "                    (layer_norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                  )\n",
            "                  (6): CLIPEncoderLayer(\n",
            "                    (self_attn): CLIPAttention(\n",
            "                      (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "                      (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "                      (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "                      (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    )\n",
            "                    (layer_norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                    (mlp): CLIPMLP(\n",
            "                      (activation_fn): QuickGELUActivation()\n",
            "                      (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                      (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                    )\n",
            "                    (layer_norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                  )\n",
            "                  (7): CLIPEncoderLayer(\n",
            "                    (self_attn): CLIPAttention(\n",
            "                      (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "                      (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "                      (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "                      (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    )\n",
            "                    (layer_norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                    (mlp): CLIPMLP(\n",
            "                      (activation_fn): QuickGELUActivation()\n",
            "                      (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                      (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                    )\n",
            "                    (layer_norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                  )\n",
            "                  (8): CLIPEncoderLayer(\n",
            "                    (self_attn): CLIPAttention(\n",
            "                      (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "                      (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "                      (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "                      (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    )\n",
            "                    (layer_norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                    (mlp): CLIPMLP(\n",
            "                      (activation_fn): QuickGELUActivation()\n",
            "                      (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                      (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                    )\n",
            "                    (layer_norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                  )\n",
            "                  (9): CLIPEncoderLayer(\n",
            "                    (self_attn): CLIPAttention(\n",
            "                      (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "                      (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "                      (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "                      (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    )\n",
            "                    (layer_norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                    (mlp): CLIPMLP(\n",
            "                      (activation_fn): QuickGELUActivation()\n",
            "                      (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                      (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                    )\n",
            "                    (layer_norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                  )\n",
            "                  (10): CLIPEncoderLayer(\n",
            "                    (self_attn): CLIPAttention(\n",
            "                      (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "                      (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "                      (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "                      (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    )\n",
            "                    (layer_norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                    (mlp): CLIPMLP(\n",
            "                      (activation_fn): QuickGELUActivation()\n",
            "                      (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                      (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                    )\n",
            "                    (layer_norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                  )\n",
            "                  (11): CLIPEncoderLayer(\n",
            "                    (self_attn): CLIPAttention(\n",
            "                      (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "                      (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "                      (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "                      (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    )\n",
            "                    (layer_norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                    (mlp): CLIPMLP(\n",
            "                      (activation_fn): QuickGELUActivation()\n",
            "                      (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                      (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                    )\n",
            "                    (layer_norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                  )\n",
            "                )\n",
            "              )\n",
            "              (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            ")\n",
            "Rank 0 Trainer build successfully.\n",
            "0it [00:00, ?it/s]model.cond_stage_key:  txt\n",
            "c.shape:  torch.Size([4, 77, 768])\n",
            "--------------------------------------------------\n",
            "Data shape for DDIM sampling is (4, 4, 64, 64), eta 0.1\n",
            "Running DDIM Sampling with 99 timesteps and 79 refinement steps\n",
            "model.cond_stage_key:  txt\n",
            "c.shape:  torch.Size([4, 77, 768])\n",
            "--------------------------------------------------\n",
            "Data shape for DDIM sampling is (4, 4, 64, 64), eta 0.1\n",
            "Running DDIM Sampling with 99 timesteps and 79 refinement steps\n",
            "best scales:\n",
            "/content/cycle-diffusion/model/gan_wrapper/stable_diffusion_stochastic_text_wrapper.py:246: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
            "  for _best_idx in best_idx\n",
            "[(1, 5, 20), (1, 5, 20), (1, 5, 20), (1, 5, 20)]\n",
            "1it [00:47, 47.74s/it]\n",
            "  0% 0/1 [00:00<?, ?it/s]encode_text: A photo of a man\n",
            "decode_text: A photo of a man shouting in excitement\n",
            "clip_score: 0.2870276868343353\n",
            "dclip_score: 0.1390296220779419\n",
            "psnr: 24.068675994873047\n",
            "ssim: 0.8748403100173027\n",
            "l2: 55.513275146484375\n",
            "--------------------------------------------------\n",
            "100% 1/1 [00:00<00:00,  3.04it/s]\n",
            "***** eval metrics *****\n",
            "  eval/avr                = 16.1766\n",
            "  eval/runtime            = 52.0548\n",
            "  eval/samples_per_second =   0.019\n",
            "  eval/steps_per_second   =   0.019\n",
            "  eval/translate/clip     =   0.287\n",
            "  eval/translate/d-clip   =   0.139\n",
            "  eval/translate/l2       = 55.5133\n",
            "  eval/translate/psnr     = 24.0687\n",
            "  eval/translate/ssim     =  0.8748\n",
            "  eval/weighted_loss      =     0.0\n",
            "  eval_samples            =       1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                eval/avr ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            eval/runtime ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: eval/samples_per_second ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   eval/steps_per_second ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:     eval/translate/clip ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   eval/translate/d-clip ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       eval/translate/l2 ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:     eval/translate/psnr ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:     eval/translate/ssim ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:      eval/weighted_loss ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                eval/avr 16.17657\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            eval/runtime 52.0548\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: eval/samples_per_second 0.019\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   eval/steps_per_second 0.019\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:     eval/translate/clip 0.28703\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   eval/translate/d-clip 0.13903\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       eval/translate/l2 55.51328\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:     eval/translate/psnr 24.06868\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:     eval/translate/ssim 0.87484\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:      eval/weighted_loss 0.0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mtranslate_text2img256_stable_diffusion_stochastic_custom_11\u001b[0m: \u001b[34m\u001b[4mhttps://wandb.ai/nagolinc/test/runs/b6q4ho71\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20221021_195025-b6q4ho71/logs\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tLfRQPpP_Lyi"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}